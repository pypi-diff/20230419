# Comparing `tmp/csvcubed-0.3.5-py3-none-any.whl.zip` & `tmp/csvcubed-0.3.6-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,8 +1,8 @@
-Zip file size: 211793 bytes, number of entries: 180
+Zip file size: 212061 bytes, number of entries: 180
 -rw-r--r--  2.0 unx     1515 b- defN 80-Jan-01 00:00 csvcubed/README.md
 -rw-r--r--  2.0 unx      218 b- defN 80-Jan-01 00:00 csvcubed/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/cli/__init__.py
 -rw-r--r--  2.0 unx     2876 b- defN 80-Jan-01 00:00 csvcubed/cli/build.py
 -rw-r--r--  2.0 unx     1414 b- defN 80-Jan-01 00:00 csvcubed/cli/build_code_list.py
 -rw-r--r--  2.0 unx     4800 b- defN 80-Jan-01 00:00 csvcubed/cli/entrypoint.py
 -rw-r--r--  2.0 unx     9572 b- defN 80-Jan-01 00:00 csvcubed/cli/error_mapping.py
@@ -20,23 +20,23 @@
 -rw-r--r--  2.0 unx    14542 b- defN 80-Jan-01 00:00 csvcubed/models/csvcubedexception.py
 -rw-r--r--  2.0 unx      409 b- defN 80-Jan-01 00:00 csvcubed/models/csvwtype.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/models/cube/__init__.py
 -rw-r--r--  2.0 unx      676 b- defN 80-Jan-01 00:00 csvcubed/models/cube/catalog.py
 -rw-r--r--  2.0 unx     1367 b- defN 80-Jan-01 00:00 csvcubed/models/cube/columns.py
 -rw-r--r--  2.0 unx     7486 b- defN 80-Jan-01 00:00 csvcubed/models/cube/cube.py
 -rw-r--r--  2.0 unx      234 b- defN 80-Jan-01 00:00 csvcubed/models/cube/cube_shape.py
--rw-r--r--  2.0 unx    13230 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/README.md
+-rw-r--r--  2.0 unx    13122 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/README.md
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/__init__.py
 -rw-r--r--  2.0 unx     4224 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/catalog.py
 -rw-r--r--  2.0 unx     2430 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/columns.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/__init__.py
 -rw-r--r--  2.0 unx     7192 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/arbitraryrdf.py
 -rw-r--r--  2.0 unx    11530 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/attribute.py
 -rw-r--r--  2.0 unx     1832 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/attributevalue.py
--rw-r--r--  2.0 unx     7728 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/codelist.py
+-rw-r--r--  2.0 unx     5188 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/codelist.py
 -rw-r--r--  2.0 unx     2377 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/concept.py
 -rw-r--r--  2.0 unx     1052 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/constants.py
 -rw-r--r--  2.0 unx     1370 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/datastructuredefinition.py
 -rw-r--r--  2.0 unx     5431 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/dimension.py
 -rw-r--r--  2.0 unx     3419 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/measure.py
 -rw-r--r--  2.0 unx     4284 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/measuresdimension.py
 -rw-r--r--  2.0 unx     1598 b- defN 80-Jan-01 00:00 csvcubed/models/cube/qb/components/observedvalue.py
@@ -53,28 +53,28 @@
 -rw-r--r--  2.0 unx      526 b- defN 80-Jan-01 00:00 csvcubed/models/rdf/conceptschemeincatalog.py
 -rw-r--r--  2.0 unx      858 b- defN 80-Jan-01 00:00 csvcubed/models/rdf/newattributevalueresource.py
 -rw-r--r--  2.0 unx     1670 b- defN 80-Jan-01 00:00 csvcubed/models/rdf/newunitresource.py
 -rw-r--r--  2.0 unx     1188 b- defN 80-Jan-01 00:00 csvcubed/models/rdf/prov.py
 -rw-r--r--  2.0 unx      447 b- defN 80-Jan-01 00:00 csvcubed/models/rdf/qbdatasetincatalog.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/models/sparql/__init__.py
 -rw-r--r--  2.0 unx      457 b- defN 80-Jan-01 00:00 csvcubed/models/sparql/valuesbinding.py
--rw-r--r--  2.0 unx    19449 b- defN 80-Jan-01 00:00 csvcubed/models/sparqlresults.py
+-rw-r--r--  2.0 unx    20070 b- defN 80-Jan-01 00:00 csvcubed/models/sparqlresults.py
 -rw-r--r--  2.0 unx     1814 b- defN 80-Jan-01 00:00 csvcubed/models/uriidentifiable.py
 -rw-r--r--  2.0 unx     3108 b- defN 80-Jan-01 00:00 csvcubed/models/validatedmodel.py
 -rw-r--r--  2.0 unx     3167 b- defN 80-Jan-01 00:00 csvcubed/models/validationerror.py
 -rw-r--r--  2.0 unx      110 b- defN 80-Jan-01 00:00 csvcubed/readers/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/readers/catalogmetadata/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/readers/catalogmetadata/v1/__init__.py
 -rw-r--r--  2.0 unx     1637 b- defN 80-Jan-01 00:00 csvcubed/readers/catalogmetadata/v1/catalog_metadata_reader.py
 -rw-r--r--  2.0 unx     6719 b- defN 80-Jan-01 00:00 csvcubed/readers/codelistconfig/codelist_schema_versions.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/__init__.py
 -rw-r--r--  2.0 unx     4878 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/schema_versions.py
 -rw-r--r--  2.0 unx     1814 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/utils.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1/__init__.py
--rw-r--r--  2.0 unx    18797 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1/columnschema.py
+-rw-r--r--  2.0 unx    20171 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1/columnschema.py
 -rw-r--r--  2.0 unx    14157 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1/configdeserialiser.py
 -rw-r--r--  2.0 unx      629 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1/constants.py
 -rw-r--r--  2.0 unx     4071 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1/datatypes.py
 -rw-r--r--  2.0 unx     9137 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1/mapcolumntocomponent.py
 -rw-r--r--  2.0 unx      182 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/readme.md
 -rw-r--r--  2.0 unx      911 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/README.md
 -rw-r--r--  2.0 unx      210 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/calendar-day.json
@@ -94,15 +94,14 @@
 -rw-r--r--  2.0 unx      246 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/gregorian-interval.json
 -rw-r--r--  2.0 unx      345 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/mixed-period.json
 -rw-r--r--  2.0 unx      144 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/observation-status.json
 -rw-r--r--  2.0 unx      826 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/preset_column_config.json
 -rw-r--r--  2.0 unx       95 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/qudt-units.json
 -rw-r--r--  2.0 unx      270 b- defN 80-Jan-01 00:00 csvcubed/readers/cubeconfig/v1_0/templates/statistical-geography.json
 -rw-r--r--  2.0 unx     3942 b- defN 80-Jan-01 00:00 csvcubed/readers/preconfiguredtemplates.py
--rw-r--r--  2.0 unx     2267 b- defN 80-Jan-01 00:00 csvcubed/readers/skoscodelistreader.py
 -rw-r--r--  2.0 unx     1647 b- defN 80-Jan-01 00:00 csvcubed/schema/codelist-config/v1_0/codelistconfig-example.jsonc
 -rw-r--r--  2.0 unx     4941 b- defN 80-Jan-01 00:00 csvcubed/schema/codelist-config/v1_0/schema.json
 -rw-r--r--  2.0 unx     6597 b- defN 80-Jan-01 00:00 csvcubed/schema/codelist-config/v1_1/schema.json
 -rw-r--r--  2.0 unx    11497 b- defN 80-Jan-01 00:00 csvcubed/schema/cube-config/v1_0/qbconfig-example.jsonc
 -rw-r--r--  2.0 unx    23488 b- defN 80-Jan-01 00:00 csvcubed/schema/cube-config/v1_0/schema.json
 -rw-r--r--  2.0 unx    11153 b- defN 80-Jan-01 00:00 csvcubed/schema/cube-config/v1_1/qbconfig-example.jsonc
 -rw-r--r--  2.0 unx    25257 b- defN 80-Jan-01 00:00 csvcubed/schema/cube-config/v1_1/schema.json
@@ -116,67 +115,68 @@
 -rw-r--r--  2.0 unx    14033 b- defN 80-Jan-01 00:00 csvcubed/utils/csvdataset.py
 -rw-r--r--  2.0 unx     4518 b- defN 80-Jan-01 00:00 csvcubed/utils/csvw.py
 -rw-r--r--  2.0 unx      453 b- defN 80-Jan-01 00:00 csvcubed/utils/datetime.py
 -rw-r--r--  2.0 unx     1488 b- defN 80-Jan-01 00:00 csvcubed/utils/dict.py
 -rw-r--r--  2.0 unx     1682 b- defN 80-Jan-01 00:00 csvcubed/utils/file.py
 -rw-r--r--  2.0 unx     1582 b- defN 80-Jan-01 00:00 csvcubed/utils/iterables.py
 -rw-r--r--  2.0 unx     4253 b- defN 80-Jan-01 00:00 csvcubed/utils/json.py
--rw-r--r--  2.0 unx     3395 b- defN 80-Jan-01 00:00 csvcubed/utils/log.py
--rw-r--r--  2.0 unx     1556 b- defN 80-Jan-01 00:00 csvcubed/utils/pandas.py
+-rw-r--r--  2.0 unx     3333 b- defN 80-Jan-01 00:00 csvcubed/utils/log.py
+-rw-r--r--  2.0 unx     1783 b- defN 80-Jan-01 00:00 csvcubed/utils/pandas.py
 -rw-r--r--  2.0 unx     1169 b- defN 80-Jan-01 00:00 csvcubed/utils/printable.py
 -rw-r--r--  2.0 unx       41 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/__init__.py
 -rw-r--r--  2.0 unx     4228 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/components.py
 -rw-r--r--  2.0 unx     3512 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/cube.py
 -rw-r--r--  2.0 unx     8509 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/standardise.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/validation/__init__.py
 -rw-r--r--  2.0 unx     2983 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/validation/cube.py
 -rw-r--r--  2.0 unx    18273 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/validation/observations.py
 -rw-r--r--  2.0 unx     1672 b- defN 80-Jan-01 00:00 csvcubed/utils/qb/validation/uri_safe.py
 -rw-r--r--  2.0 unx     1945 b- defN 80-Jan-01 00:00 csvcubed/utils/rdf.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/utils/skos/__init__.py
 -rw-r--r--  2.0 unx     3017 b- defN 80-Jan-01 00:00 csvcubed/utils/skos/codelist.py
 -rw-r--r--  2.0 unx       89 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/__init__.py
--rw-r--r--  2.0 unx     4121 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/code_list_inspector.py
+-rw-r--r--  2.0 unx     6289 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/code_list_inspector.py
 -rw-r--r--  2.0 unx      955 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/column_component_info.py
 -rw-r--r--  2.0 unx     4583 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/csvw_inspector.py
--rw-r--r--  2.0 unx    13992 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/data_cube_inspector.py
+-rw-r--r--  2.0 unx    18992 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/data_cube_inspector.py
 -rw-r--r--  2.0 unx     3889 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql.py
 -rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/ask_is_codelist.sparql
 -rw-r--r--  2.0 unx       75 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/ask_is_qb_dataset.sparql
 -rw-r--r--  2.0 unx     2298 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_catalog_metadata.sparql
 -rw-r--r--  2.0 unx     1006 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_csv_url.sparql
 -rw-r--r--  2.0 unx      482 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_primary_key_by_csv_url.sparql
 -rw-r--r--  2.0 unx      969 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_codelists_and_cols.sparql
 -rw-r--r--  2.0 unx     2149 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_column_definitions.sparql
 -rw-r--r--  2.0 unx      354 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_csvw_table_schema_file_dependencies.sparql
 -rw-r--r--  2.0 unx     1188 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_data_set_dsd_csv_url.sparql
 -rw-r--r--  2.0 unx     1339 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_dsd_qube_components.sparql
--rw-r--r--  2.0 unx      756 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_is_pivoted_shape_for_measures_in_data_set.sparql
+-rw-r--r--  2.0 unx      757 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_is_pivoted_shape_for_measures_in_data_set.sparql
+-rw-r--r--  2.0 unx      179 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_labels_for_resource_uris.sparql
 -rw-r--r--  2.0 unx      379 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_metadata_dependencies.sparql
 -rw-r--r--  2.0 unx      466 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_table_schema_properties.sparql
 -rw-r--r--  2.0 unx      367 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparql_queries/select_units.sparql
--rw-r--r--  2.0 unx    10794 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparqlquerymanager.py
+-rw-r--r--  2.0 unx    11626 b- defN 80-Jan-01 00:00 csvcubed/utils/sparql_handler/sparqlquerymanager.py
 -rw-r--r--  2.0 unx     8831 b- defN 80-Jan-01 00:00 csvcubed/utils/tableschema.py
 -rw-r--r--  2.0 unx      356 b- defN 80-Jan-01 00:00 csvcubed/utils/text.py
 -rw-r--r--  2.0 unx     3467 b- defN 80-Jan-01 00:00 csvcubed/utils/uri.py
 -rw-r--r--  2.0 unx    11239 b- defN 80-Jan-01 00:00 csvcubed/utils/validations.py
 -rw-r--r--  2.0 unx       45 b- defN 80-Jan-01 00:00 csvcubed/utils/validators/__init__.py
 -rw-r--r--  2.0 unx     4360 b- defN 80-Jan-01 00:00 csvcubed/utils/validators/schema.py
 -rw-r--r--  2.0 unx      268 b- defN 80-Jan-01 00:00 csvcubed/utils/version.py
 -rw-r--r--  2.0 unx       62 b- defN 80-Jan-01 00:00 csvcubed/writers/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/__init__.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/qbwriter/__init__.py
--rw-r--r--  2.0 unx    23100 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/qbwriter/dsdtordfmodelshelper.py
+-rw-r--r--  2.0 unx    22952 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/qbwriter/dsdtordfmodelshelper.py
 -rw-r--r--  2.0 unx     3597 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/qbwriter/newresourceurigenerator.py
--rw-r--r--  2.0 unx    27748 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/qbwriter/urihelper.py
+-rw-r--r--  2.0 unx    27378 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/qbwriter/urihelper.py
 -rw-r--r--  2.0 unx        0 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/skoscodelistwriter/__init__.py
 -rw-r--r--  2.0 unx      157 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/skoscodelistwriter/constants.py
 -rw-r--r--  2.0 unx     2437 b- defN 80-Jan-01 00:00 csvcubed/writers/helpers/skoscodelistwriter/newresourceurigenerator.py
--rw-r--r--  2.0 unx    23393 b- defN 80-Jan-01 00:00 csvcubed/writers/qbwriter.py
--rw-r--r--  2.0 unx     9173 b- defN 80-Jan-01 00:00 csvcubed/writers/skoscodelistwriter.py
+-rw-r--r--  2.0 unx    20804 b- defN 80-Jan-01 00:00 csvcubed/writers/qbwriter.py
+-rw-r--r--  2.0 unx     9470 b- defN 80-Jan-01 00:00 csvcubed/writers/skoscodelistwriter.py
 -rw-r--r--  2.0 unx      283 b- defN 80-Jan-01 00:00 csvcubed/writers/writerbase.py
--rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 csvcubed-0.3.5.dist-info/LICENSE
--rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 csvcubed-0.3.5.dist-info/WHEEL
--rw-r--r--  2.0 unx       64 b- defN 80-Jan-01 00:00 csvcubed-0.3.5.dist-info/entry_points.txt
--rw-r--r--  2.0 unx     3925 b- defN 80-Jan-01 00:00 csvcubed-0.3.5.dist-info/METADATA
-?rw-r--r--  2.0 unx    18059 b- defN 16-Jan-01 00:00 csvcubed-0.3.5.dist-info/RECORD
-180 files, 763949 bytes uncompressed, 182189 bytes compressed:  76.2%
+-rw-r--r--  2.0 unx    11357 b- defN 80-Jan-01 00:00 csvcubed-0.3.6.dist-info/LICENSE
+-rw-r--r--  2.0 unx     3925 b- defN 80-Jan-01 00:00 csvcubed-0.3.6.dist-info/METADATA
+-rw-r--r--  2.0 unx       88 b- defN 80-Jan-01 00:00 csvcubed-0.3.6.dist-info/WHEEL
+-rw-r--r--  2.0 unx       64 b- defN 80-Jan-01 00:00 csvcubed-0.3.6.dist-info/entry_points.txt
+?rw-r--r--  2.0 unx    18103 b- defN 16-Jan-01 00:00 csvcubed-0.3.6.dist-info/RECORD
+180 files, 766608 bytes uncompressed, 182367 bytes compressed:  76.2%
```

## zipnote {}

```diff
@@ -291,17 +291,14 @@
 
 Filename: csvcubed/readers/cubeconfig/v1_0/templates/statistical-geography.json
 Comment: 
 
 Filename: csvcubed/readers/preconfiguredtemplates.py
 Comment: 
 
-Filename: csvcubed/readers/skoscodelistreader.py
-Comment: 
-
 Filename: csvcubed/schema/codelist-config/v1_0/codelistconfig-example.jsonc
 Comment: 
 
 Filename: csvcubed/schema/codelist-config/v1_0/schema.json
 Comment: 
 
 Filename: csvcubed/schema/codelist-config/v1_1/schema.json
@@ -450,14 +447,17 @@
 
 Filename: csvcubed/utils/sparql_handler/sparql_queries/select_dsd_qube_components.sparql
 Comment: 
 
 Filename: csvcubed/utils/sparql_handler/sparql_queries/select_is_pivoted_shape_for_measures_in_data_set.sparql
 Comment: 
 
+Filename: csvcubed/utils/sparql_handler/sparql_queries/select_labels_for_resource_uris.sparql
+Comment: 
+
 Filename: csvcubed/utils/sparql_handler/sparql_queries/select_metadata_dependencies.sparql
 Comment: 
 
 Filename: csvcubed/utils/sparql_handler/sparql_queries/select_table_schema_properties.sparql
 Comment: 
 
 Filename: csvcubed/utils/sparql_handler/sparql_queries/select_units.sparql
@@ -519,23 +519,23 @@
 
 Filename: csvcubed/writers/skoscodelistwriter.py
 Comment: 
 
 Filename: csvcubed/writers/writerbase.py
 Comment: 
 
-Filename: csvcubed-0.3.5.dist-info/LICENSE
+Filename: csvcubed-0.3.6.dist-info/LICENSE
 Comment: 
 
-Filename: csvcubed-0.3.5.dist-info/WHEEL
+Filename: csvcubed-0.3.6.dist-info/METADATA
 Comment: 
 
-Filename: csvcubed-0.3.5.dist-info/entry_points.txt
+Filename: csvcubed-0.3.6.dist-info/WHEEL
 Comment: 
 
-Filename: csvcubed-0.3.5.dist-info/METADATA
+Filename: csvcubed-0.3.6.dist-info/entry_points.txt
 Comment: 
 
-Filename: csvcubed-0.3.5.dist-info/RECORD
+Filename: csvcubed-0.3.6.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## csvcubed/models/cube/qb/README.md

```diff
@@ -129,16 +129,15 @@
 ```text
 SecondaryQbStructuralDefinition
 ├── QbAttributeValue        - Stored against the QbAttribute. Represents a (URI) value that an attribute can have.
 │   └── NewQbAttributeValue     - Define a new URI value which an attribute can hold.
 ├── QbCodeList              - Stored against the QbDimension. Holds a `skos:ConceptScheme` which lists the values the dimension can have.
 │   ├── ExistingQbCodeList      - Reuse a code-list defined elsewhere.
 │   ├── NewQbCodeList           - Define a new code-list.
-│   ├── CompositeQbCodeList     - Define a new code-list which is a composite of `skos:Concept`s defined in other code-lists.
-│   └── NewQbCodeListInCsvW     - Use a code-list which is already generated and stored in a CSV-W.
+│   └── CompositeQbCodeList     - Define a new code-list which is a composite of `skos:Concept`s defined in other code-lists.
 ├── QbConcept               - Stored against the QbCodeList. It holds a concept contained in a `skos:ConceptScheme`.
 │   ├── NewQbConcept            - Define a new concept
 │   └── DuplicatedQbConcept     - Reuse a concept defined elsewhere. This permits altering its label/notation/structure.
 ├── QbMeasure               - Stored against the QbObservation OR QbMultiMeasureDimension. Represents an observation's measure.
 │   ├── ExistingQbMeasure       - Reuse a measure defined elsewhere.
 │   └── NewQbMeasure            - Define a new measure.
 └── QbUnit                  - Stored against the QbObservation OR QbMultiUnits. Represents an observation's unit.
```

## csvcubed/models/cube/qb/components/codelist.py

```diff
@@ -3,25 +3,24 @@
 ----------
 
 Represent code lists in an RDF Data Cube.
 """
 from abc import ABC
 from dataclasses import dataclass, field
 from pathlib import Path
-from typing import Dict, Generic, List, Optional, Set, TypeVar, Union
+from typing import Dict, Generic, List, Optional, Set, TypeVar
 
 from csvcubed.inputs import PandasDataTypes, pandas_input_to_columnar_str
 from csvcubed.models.cube.qb.catalog import CatalogMetadata
-from csvcubed.models.validatedmodel import ValidationFunction, Validations
+from csvcubed.models.validatedmodel import ValidationFunction
 from csvcubed.models.validationerror import (
     ReservedUriValueError,
     ValidateModelPropertiesError,
     ValidationError,
 )
-from csvcubed.readers.skoscodelistreader import extract_code_list_concept_scheme_info
 from csvcubed.utils import validations as v
 from csvcubed.utils.qb.validation.uri_safe import ensure_no_uri_safe_conflicts
 from csvcubed.writers.helpers.skoscodelistwriter.constants import SCHEMA_URI_IDENTIFIER
 
 from ...uristyle import URIStyle
 from .arbitraryrdf import ArbitraryRdf, RdfSerialisationHint, TripleFragmentBase
 from .concept import DuplicatedQbConcept, NewQbConcept
@@ -41,76 +40,14 @@
 
     concept_scheme_uri: str
 
     def _get_validations(self) -> Dict[str, ValidationFunction]:
         return {"concept_scheme_uri": v.uri}
 
 
-@dataclass
-class NewQbCodeListInCsvW(QbCodeList):
-    """
-    Contains the reference to an existing skos:ConceptScheme defined in a CSV-W.
-    """
-
-    schema_metadata_file_path: Path
-    csv_file_relative_path_or_uri: str = field(init=False, repr=False)
-    concept_scheme_uri: str = field(init=False, repr=False)
-    concept_template_uri: str = field(init=False, repr=False)
-
-    def __post_init__(self):
-        try:
-            (
-                csv_url,
-                cs_uri,
-                concept_template_uri,
-            ) = extract_code_list_concept_scheme_info(self.schema_metadata_file_path)
-            self.csv_file_relative_path_or_uri = csv_url
-            self.concept_scheme_uri = cs_uri
-            self.concept_template_uri = concept_template_uri
-        except Exception:
-            # Validation errors will be highlighted later in custom validation function.
-            self.csv_file_relative_path_or_uri = None  # type: ignore
-            self.concept_scheme_uri = None  # type: ignore
-            self.concept_template_uri = None  # type: ignore
-
-    def _get_validations(self) -> Union[Validations, Dict[str, ValidationFunction]]:
-        return Validations(
-            individual_property_validations={
-                "schema_metadata_file_path": v.file,
-                "csv_file_relative_path_or_uri": v.string,
-                "concept_scheme_uri": v.uri,
-                "concept_template_uri": v.string,
-            },
-            whole_object_validations=[self._validation_csvw_sufficient_information],
-        )
-
-    @staticmethod
-    def _validation_csvw_sufficient_information(
-        value: "NewQbCodeListInCsvW", property_path: List[str]
-    ):
-        errors: List[ValidateModelPropertiesError] = []
-
-        csv_path = value.csv_file_relative_path_or_uri
-        cs_uri = value.concept_scheme_uri
-        c_template_uri = value.concept_template_uri
-        if csv_path is None or cs_uri is None or c_template_uri is None:
-            schema_metadata_file_path = value.schema_metadata_file_path
-            extract_code_list_concept_scheme_info(schema_metadata_file_path)
-
-            errors.append(
-                ValidateModelPropertiesError(
-                    "'csv_file_relative_path_or_uri', 'concept_scheme_uri' or 'concept_template_uri' values are missing.",
-                    property_path,
-                    value,
-                )
-            )
-
-        return errors
-
-
 TNewQbConcept = TypeVar("TNewQbConcept", bound=NewQbConcept, covariant=True)
 
 
 @dataclass
 class NewQbCodeList(QbCodeList, ArbitraryRdf, Generic[TNewQbConcept]):
     """
     Contains the metadata necessary to create a new skos:ConceptScheme which is local to a dataset.
```

## csvcubed/models/sparqlresults.py

```diff
@@ -260,14 +260,24 @@
     Model to represent select qube components sparql query result.
     """
 
     qube_components: list[QubeComponentResult]
     num_components: int
 
 
+@dataclass
+class ResourceURILabelResult:
+    """
+    Model to represent a resource attribute's URI and label.
+    """
+
+    resource_uri: str
+    resource_label: str
+
+
 def map_catalog_metadata_results(
     sparql_results: List[ResultRow],
 ) -> List[CatalogMetadataResult]:
     """
     Maps the sparql query results to a list of `CatalogMetadataResult`
 
     Member of :file:`./models/sparqlresults.py`
@@ -626,14 +636,30 @@
             measure=str(row_result["measure"]),
             is_pivoted_shape=bool(row_result["isPivotedShape"]),
         )
 
     return [map_row(row.asdict()) for row in sparql_results]
 
 
+def map_labels_for_resource_uris(
+    sparql_results: List[ResultRow],
+) -> Dict[str, str]:
+    """
+    Maps resource value uris to labels
+    """
+
+    results: Dict[str, str] = {}
+    for row in sparql_results:
+        if str(row["resourceValUri"]) in results:
+            raise KeyError("Duplicate URIs or multiple labels for URI in CSV-W")
+        else:
+            results[str(row["resourceValUri"])] = str(row["resourceLabel"])
+    return results
+
+
 def map_column_definition_results(
     sparql_results: List[ResultRow],
 ) -> List[ColumnDefinition]:
     """
     Maps SPARQL query results to 'ColumnDefinition's.
     """
```

## csvcubed/readers/cubeconfig/v1/columnschema.py

```diff
@@ -14,15 +14,14 @@
 from typing import List, Optional, Tuple, TypeVar, Union
 
 import uritemplate
 from csvcubedmodels.dataclassbase import DataClassBase
 
 from csvcubed.cli.build_code_list import get_code_list_versioned_deserialiser
 from csvcubed.inputs import PandasDataTypes, pandas_input_to_columnar_optional_str
-from csvcubed.models.codelistconfig.code_list_config import CodeListConfig
 from csvcubed.models.cube.cube import CatalogMetadata
 from csvcubed.models.cube.qb.components.attribute import (
     ExistingQbAttribute,
     ExistingQbAttributeLiteral,
     NewQbAttribute,
     NewQbAttributeLiteral,
     NewQbAttributeValue,
@@ -41,25 +40,19 @@
 )
 from csvcubed.models.cube.qb.components.measure import ExistingQbMeasure, NewQbMeasure
 from csvcubed.models.cube.qb.components.measuresdimension import QbMultiMeasureDimension
 from csvcubed.models.cube.qb.components.observedvalue import QbObservationValue
 from csvcubed.models.cube.qb.components.unit import ExistingQbUnit, NewQbUnit
 from csvcubed.models.cube.qb.components.unitscolumn import QbMultiUnits
 from csvcubed.models.jsonvalidationerrors import JsonSchemaValidationError
-from csvcubed.models.validationerror import ValidationError
 from csvcubed.readers.codelistconfig.codelist_schema_versions import (
     LATEST_V1_CODELIST_SCHEMA_URL,
 )
-from csvcubed.readers.cubeconfig.utils import load_resource
 from csvcubed.utils.file import code_list_config_json_exists
 from csvcubed.utils.uri import csvw_column_name_safe, looks_like_uri
-from csvcubed.utils.validators.schema import (
-    map_to_internal_validation_errors,
-    validate_dict_against_schema,
-)
 
 _logger = logging.getLogger(__name__)
 
 T = TypeVar("T", bound=object)
 
 EXISTING_UNIT_DEFAULT_SCALING_FACTOR = 1.0
 
@@ -86,15 +79,14 @@
     def map_to_new_qb_dimension(
         self,
         csv_column_title: str,
         data: PandasDataTypes,
         cube_config_minor_version: Optional[int],
         config_path: Optional[Path] = None,
     ) -> Tuple[NewQbDimension, List[JsonSchemaValidationError]]:
-
         new_dimension = NewQbDimension.from_data(
             label=self.label or csv_column_title,
             data=data,
             description=self.description,
             parent_dimension_uri=self.from_existing,
             source_uri=self.definition_uri,
         )
@@ -243,15 +235,14 @@
 class ExistingAttributeLiteral(SchemaBaseClass):
     from_existing: str
     data_type: str
     required: bool = False
     describes_observations: Optional[str] = None
 
     def map_to_existing_qb_attribute(self) -> ExistingQbAttributeLiteral:
-
         return ExistingQbAttributeLiteral(
             attribute_uri=self.from_existing,
             is_required=self.required,
             data_type=self.data_type,
             observed_value_col_title=self.describes_observations,
         )
 
@@ -263,21 +254,34 @@
     required: bool = False
     cell_uri_template: Optional[str] = None
     describes_observations: Optional[str] = None
 
     def map_to_existing_qb_attribute(
         self, data: PandasDataTypes
     ) -> ExistingQbAttribute:
-
-        return ExistingQbAttribute(
-            self.from_existing,
-            new_attribute_values=_get_new_attribute_values(data, self.values),
-            is_required=self.required,
-            observed_value_col_title=self.describes_observations,
-        )
+        if self.cell_uri_template:
+            if isinstance(self.values, bool):
+                _logger.warning(
+                    "Attribute values will not be created as `cell_uri_template` is set"
+                )
+                return ExistingQbAttribute(
+                    attribute_uri=self.from_existing,
+                    is_required=self.required,
+                    observed_value_col_title=self.describes_observations,
+                )
+            raise ValueError(
+                "Conflict between `cell_uri_template` and list of attribute values provided"
+            )
+        else:
+            return ExistingQbAttribute(
+                attribute_uri=self.from_existing,
+                new_attribute_values=_get_new_attribute_values(data, self.values),
+                is_required=self.required,
+                observed_value_col_title=self.describes_observations,
+            )
 
 
 @dataclass
 class NewAttributeLiteral(SchemaBaseClass):
     data_type: str
     label: Optional[str] = None
     description: Optional[str] = None
@@ -312,23 +316,41 @@
     describes_observations: Optional[str] = None
 
     def map_to_new_qb_attribute(
         self, column_title: str, data: PandasDataTypes
     ) -> NewQbAttribute:
         label = self.label or column_title
 
-        return NewQbAttribute(
-            label=label,
-            description=self.description,
-            new_attribute_values=_get_new_attribute_values(data, self.values),
-            parent_attribute_uri=self.from_existing,
-            source_uri=self.definition_uri,
-            is_required=self.required,
-            observed_value_col_title=self.describes_observations,
-        )
+        if self.cell_uri_template:
+            if isinstance(self.values, bool):
+                _logger.warning(
+                    "Attribute values will not be created as `cell_uri_template` is set"
+                )
+                return NewQbAttribute(
+                    label=label,
+                    description=self.description,
+                    parent_attribute_uri=self.from_existing,
+                    source_uri=self.definition_uri,
+                    is_required=self.required,
+                    observed_value_col_title=self.describes_observations,
+                )
+
+            raise ValueError(
+                "Conflict between `cell_uri_template` and list of attribute values provided"
+            )
+        else:
+            return NewQbAttribute(
+                label=label,
+                description=self.description,
+                new_attribute_values=_get_new_attribute_values(data, self.values),
+                parent_attribute_uri=self.from_existing,
+                source_uri=self.definition_uri,
+                is_required=self.required,
+                observed_value_col_title=self.describes_observations,
+            )
 
 
 @dataclass
 class Unit(SchemaBaseClass):
     label: str
     description: Optional[str] = None
     from_existing: Optional[str] = None
@@ -362,15 +384,14 @@
     def map_to_new_qb_multi_units(self, data: PandasDataTypes) -> QbMultiUnits:
         if isinstance(self.values, bool) and self.values is True:
             return QbMultiUnits.new_units_from_data(
                 data, observed_value_col_title=self.describes_observations
             )
 
         elif isinstance(self.values, list):
-
             units = []
             for unit in self.values:
                 if not isinstance(unit, Unit):
                     raise ValueError(f"Unexpected unit value: {unit}")
 
                 units.append(_map_unit(unit))
 
@@ -528,14 +549,20 @@
         return unit.scaling_factor
 
 
 def _get_new_attribute_values(
     data: PandasDataTypes,
     new_attribute_values: Union[bool, List[AttributeValue]],
 ) -> List[NewQbAttributeValue]:
+    """
+    Returns a list of new attribute value objects. If cell_uri_template is True, then the list is created with
+    the list comprehension. If cell_uri_template is not used (new_attribute_values is a list object)
+    then use _map_attribute_values.
+    """
+
     if isinstance(new_attribute_values, bool):
         if new_attribute_values:
             columnar_data: List[str] = [
                 v for v in pandas_input_to_columnar_optional_str(data) if v is not None
             ]
             return [NewQbAttributeValue(v) for v in sorted(set(columnar_data))]
```

## csvcubed/utils/log.py

```diff
@@ -11,15 +11,14 @@
 from pathlib import Path
 from typing import Union
 
 from appdirs import AppDirs
 
 
 class CustomFormatter(logging.Formatter):
-
     grey = "\x1b[2;20m"
     light_grey = "\x1b[1;50m"
     yellow = "\x1b[33;20m"
     red = "\x1b[31;20m"
     bold_red = "\x1b[31;1m"
     reset = "\x1b[0m"
     formatting = (
@@ -37,25 +36,23 @@
     def format(self, record):
         log_fmt = self.FORMATS.get(record.levelno)
         formatter = logging.Formatter(log_fmt)
         return formatter.format(record)
 
 
 def start_logging(
-    log_dir_name: str,
-    selected_logging_level: Union[str, int, None],
-    root_logger_name: str = "csvcubed",
+    log_dir_name: str, selected_logging_level: Union[str, int, None]
 ) -> None:
     logging_level = _get_logging_level(selected_logging_level)
 
     dirs = AppDirs(log_dir_name, "csvcubed")
     log_file_path = Path(dirs.user_log_dir) / "out.log"
     log_file_path.parent.mkdir(parents=True, exist_ok=True)
 
-    logger = logging.getLogger(root_logger_name)
+    logger = logging.getLogger()
     logger.setLevel(logging_level)
 
     console_handler = logging.StreamHandler(sys.stderr)
     console_handler.setLevel(logging_level)
     console_handler.setFormatter(CustomFormatter())
 
     file_handler = logging.handlers.TimedRotatingFileHandler(
```

## csvcubed/utils/pandas.py

```diff
@@ -2,50 +2,59 @@
 Pandas Utils
 ------------
 
 This file provides additional utilities for pandas type commands
 """
 import logging
 from pathlib import Path
-from typing import List, Tuple
+from typing import Dict, List, Optional, Set, Tuple, Union
 
 import pandas as pd
+from numpy import dtype
 
 from csvcubed.models.cube.validationerrors import DuplicateColumnTitleError
 from csvcubed.models.validationerror import ValidationError
 
 _logger = logging.getLogger(__name__)
 
 # Values used in place of NA in dataframe reads
 SPECIFIED_NA_VALUES = {
     "",
 }
 
 
 def read_csv(
-    csv_path: Path, keep_default_na=False, na_values=SPECIFIED_NA_VALUES, dtype=None
+    csv_path_or_url: Union[Path, str],
+    keep_default_na: bool = False,
+    na_values: Set[str] = SPECIFIED_NA_VALUES,
+    dtype: Optional[Dict] = None,
+    usecols: Optional[List[str]] = None,
 ) -> Tuple[pd.DataFrame, List[ValidationError]]:
     """
     :returns: a tuple of
         pd.DataFrame without the default na values being changes into NaN
         list of ValidationExceptions
     """
 
     df = pd.read_csv(
-        csv_path, keep_default_na=keep_default_na, na_values=na_values, dtype=dtype
+        csv_path_or_url,
+        keep_default_na=keep_default_na,
+        na_values=na_values,
+        dtype=dtype,
+        usecols=usecols,
     )
     if not isinstance(df, pd.DataFrame):
         _logger.debug(
             "Expected a pandas dataframe when reading from CSV, value was %s", df
         )
         raise ValueError(
             f"Expected a pandas dataframe when reading from CSV, value was {type(df)}"
         )
 
     # Read first row as values rather than headers, so we can check for duplicate column titles
-    col_title_counts = pd.read_csv(csv_path, header=None, nrows=1).iloc[0, :].value_counts()  # type: ignore
+    col_title_counts = pd.read_csv(csv_path_or_url, header=None, nrows=1).iloc[0, :].value_counts()  # type: ignore
     duplicate_titles = list(col_title_counts[col_title_counts > 1].keys())
 
     return df, [
         DuplicateColumnTitleError(csv_column_title=dupe_title)
         for dupe_title in duplicate_titles
     ]
```

## csvcubed/utils/sparql_handler/code_list_inspector.py

```diff
@@ -3,25 +3,33 @@
 -------------------
 
 This module contains the `CodeListInspector` class which allows API-style access to information
 about code lists contained within an RDF graph.
 """
 from dataclasses import dataclass
 from functools import cached_property
-from typing import List, Optional
+from typing import Dict, List, Optional
+from urllib.parse import urljoin, urlparse
 
 from csvcubedmodels.rdf.namespaces import SKOS
 
 from csvcubed.models.sparqlresults import (
     CatalogMetadataResult,
     CodeListTableIdentifers,
     ColumnDefinition,
 )
 from csvcubed.utils.iterables import first
+from csvcubed.utils.pandas import read_csv
 from csvcubed.utils.sparql_handler.csvw_inspector import CsvWInspector
+from csvcubed.utils.text import truncate
+from csvcubed.utils.uri import file_uri_to_path, looks_like_uri
+from csvcubed.writers.skoscodelistwriter import (
+    LABEL_COL_TITLE,
+    URI_IDENTIFIER_COL_TITLE,
+)
 
 
 @dataclass
 class CodeListInspector:
     """
     Allows API-style access to information about code lists contained within an RDF graph.
     """
@@ -97,14 +105,62 @@
         if result is None:
             raise KeyError(
                 f"Can not find Catalogue Meatadata associated with the concept scheme URL '{concept_scheme_url}'."
             )
 
         return result
 
+    def get_map_code_list_uri_to_label(self, concept_scheme_uri: str) -> Dict[str, str]:
+        """
+        Maps the code list's Uri Identifiers to human-readable labels
+        """
+        csv_url = self.get_table_identifiers_for_concept_scheme(
+            concept_scheme_uri
+        ).csv_url
+
+        if looks_like_uri(csv_url):
+            if urlparse(csv_url).scheme == "file":
+                # pandas expects local file URLs to be in the format `file://localhost/path/to/table.csv.`
+                absolute_csv_url = file_uri_to_path(csv_url)
+            else:
+                absolute_csv_url = csv_url
+        else:
+            absolute_csv_url = file_uri_to_path(
+                urljoin(self.csvw_inspector.csvw_json_path.as_uri(), csv_url)
+            )
+
+        (dataframe, _) = read_csv(
+            absolute_csv_url, usecols=[URI_IDENTIFIER_COL_TITLE, LABEL_COL_TITLE]
+        )
+
+        duplicated_uris = dataframe[
+            dataframe[URI_IDENTIFIER_COL_TITLE].duplicated() == True
+        ]
+        duplicated_labels = dataframe[dataframe[LABEL_COL_TITLE].duplicated() == True]
+        if duplicated_uris.size > 0:
+            duplicate_uris: str = truncate(
+                ", ".join(duplicated_uris[URI_IDENTIFIER_COL_TITLE]), 50
+            )
+            raise ValueError(
+                f"Duplicate URIs '{duplicate_uris}' in `Uri Identifier` column for {csv_url}"
+            )
+        elif duplicated_labels.size > 0:
+            duplicate_labels: str = truncate(
+                ", ".join(duplicated_labels[LABEL_COL_TITLE]), 50
+            )
+            raise ValueError(
+                f"Duplicate labels '{duplicate_labels}' in `Label` column for {csv_url}"
+            )
+
+        dict_uri_to_label = dict(
+            zip(dataframe[URI_IDENTIFIER_COL_TITLE], dataframe[LABEL_COL_TITLE])
+        )
+
+        return dict_uri_to_label
+
     def get_primary_csv_url(self) -> str:
         """
         Retrieves the csv_url for the primary CSV defined in the CSV-W.
         This will only work if the primary file loaded into the graph was a
         code list.
         """
         primary_catalog_metadata = self.csvw_inspector.get_primary_catalog_metadata()
```

## csvcubed/utils/sparql_handler/data_cube_inspector.py

```diff
@@ -1,23 +1,26 @@
 """
 Data Cube Inspector
 -------------------
 
 Provides access to inspect the contents of an rdflib graph containing
 one of more data cubes.
 """
+
 from dataclasses import dataclass
 from functools import cache, cached_property
 from typing import Dict, List, Optional, Set, Tuple
 from urllib.parse import urljoin
 
 import pandas as pd
+import uritemplate
 from csvcubedmodels.rdf.namespaces import XSD
 
 from csvcubed.definitions import QB_MEASURE_TYPE_DIMENSION_URI, SDMX_ATTRIBUTE_UNIT_URI
+from csvcubed.inputs import pandas_input_to_columnar_str
 from csvcubed.models.csvcubedexception import UnsupportedComponentPropertyTypeException
 from csvcubed.models.cube.cube_shape import CubeShape
 from csvcubed.models.cube.qb.components.constants import ACCEPTED_DATATYPE_MAPPING
 from csvcubed.models.sparqlresults import (
     CodelistsResult,
     ColumnDefinition,
     CubeTableIdentifiers,
@@ -34,14 +37,15 @@
 from csvcubed.utils.sparql_handler.column_component_info import ColumnComponentInfo
 from csvcubed.utils.sparql_handler.csvw_inspector import CsvWInspector
 from csvcubed.utils.sparql_handler.sparqlquerymanager import (
     select_csvw_dsd_qube_components,
     select_data_set_dsd_and_csv_url,
     select_dsd_code_list_and_cols,
     select_is_pivoted_shape_for_measures_in_data_set,
+    select_labels_for_resource_uris,
     select_units,
 )
 from csvcubed.utils.uri import file_uri_to_path
 
 _XSD_BASE_URI: str = XSD[""].toPython()
 
 
@@ -212,27 +216,14 @@
     def get_code_lists_and_cols(self, csv_url: str) -> CodelistsResult:
         """
         Get the codelists and columns associated with the given csv url.
         """
 
         return self._codelists_and_cols.get(csv_url, CodelistsResult([], 0))
 
-    def get_dataframe(self, csv_url: str) -> Tuple[pd.DataFrame, List[ValidationError]]:
-        """
-        Get the pandas dataframe for the csv url of the cube wishing to be loaded.
-        Returns DuplicateColumnTitleError in the event of two instances of the
-        same columns being defined.
-        """
-        cols = self.get_column_component_info(csv_url)
-        dict_of_types = _get_data_types_of_all_cols(cols)
-        absolute_csv_url = file_uri_to_path(
-            urljoin(self.csvw_inspector.csvw_json_path.as_uri(), csv_url)
-        )
-        return read_csv(absolute_csv_url, dtype=dict_of_types)
-
     @cache
     def get_column_component_info(self, csv_url: str) -> List[ColumnComponentInfo]:
         """
         Gets a list of columns in the requested CSV file, their types (in the nomenclature of the qube-config.json
           format), and an RDF Data Cube DataStructureDefinition component directly associated with them.
 
         Columns are defined in the same order as in the CSV file.
@@ -277,35 +268,172 @@
         """
         return [
             c.column_definition
             for c in self.get_column_component_info(csv_url)
             if c.column_type == column_type
         ]
 
+    def get_measure_uris_and_labels(self, csv_url: str) -> Dict[str, str]:
+        """
+        Returns a dictionary containing the measure URIs and labels from the input csv's qube components.
+        """
+        qube_components = self.get_dsd_qube_components_for_csv(csv_url).qube_components
+
+        results_dict = {}
+        for component in qube_components:
+            if component.property_type == ComponentPropertyType.Measure.value:
+                results_dict[component.property] = component.property_label
+
+        return results_dict
+
+    def get_attribute_value_uris_and_labels(
+        self, csv_url: str
+    ) -> Dict[str, Dict[str, str]]:
+        """
+        Returns a dictionary of the column name mapped to a dictionary of attribute value uris and their labels
+        """
+        (
+            map_col_name_to_title,
+            map_resource_attr_col_name_to_value_url,
+        ) = self._map_column_name_to_title_to_attribute_value_url(csv_url)
+
+        map_col_name_to_attr_val_uris = self._map_col_name_to_attr_val_uris(
+            csv_url, map_col_name_to_title, map_resource_attr_col_name_to_value_url
+        )
+
+        return self._map_col_title_to_attr_val_uris_and_labels(
+            map_col_name_to_attr_val_uris, map_col_name_to_title
+        )
+
     def get_primary_csv_url(self) -> str:
         """
         Retrieves the csv_url for the primary CSV defined in the CSV-W.
         This will only work if the primary file loaded into the graph was a
         data cube.
         """
         primary_catalog_metadata = self.csvw_inspector.get_primary_catalog_metadata()
         return self.get_cube_identifiers_for_data_set(
             primary_catalog_metadata.dataset_uri
         ).csv_url
 
+    def get_dataframe(self, csv_url: str) -> Tuple[pd.DataFrame, List[ValidationError]]:
+        """
+        Get the pandas dataframe for the csv url of the cube wishing to be loaded.
+        Returns DuplicateColumnTitleError in the event of two instances of the
+        same columns being defined.
+        """
+        cols = self.get_column_component_info(csv_url)
+        dict_of_types = _get_data_types_of_all_cols(cols)
+        absolute_csv_url = file_uri_to_path(
+            urljoin(self.csvw_inspector.csvw_json_path.as_uri(), csv_url)
+        )
+        return read_csv(absolute_csv_url, dtype=dict_of_types)
+
+    def _map_column_name_to_title_to_attribute_value_url(
+        self, csv_url: str
+    ) -> Tuple[Dict[str, str], Dict[str, str]]:
+        """
+        Returns dictionaries of column name to column title and resource attribute column name to value url
+        """
+        column_components = self.get_column_component_info(csv_url)
+
+        map_col_name_to_title = {
+            component.column_definition.name: component.column_definition.title
+            for component in column_components
+            if component.column_definition.name is not None
+            and component.column_definition.title is not None
+        }
+
+        map_resource_attr_col_name_to_value_url = {
+            component.column_definition.name: component.column_definition.value_url
+            for component in column_components
+            if component.column_type == EndUserColumnType.Attribute
+            and component.column_definition.name is not None
+            and component.column_definition.value_url is not None
+        }
+
+        return (map_col_name_to_title, map_resource_attr_col_name_to_value_url)
+
+    def _map_col_name_to_attr_val_uris(
+        self,
+        csv_url,
+        map_col_name_to_title: Dict[str, str],
+        map_resource_attr_col_name_to_value_url: Dict[str, str],
+    ) -> Dict[str, List[str]]:
+        """
+        Returns a dictionary of column name mapped to a list of all attribute value uris for that column
+        """
+        absolute_csv_url = file_uri_to_path(
+            urljoin(self.csvw_inspector.csvw_json_path.as_uri(), csv_url)
+        )
+        (dataframe, _) = read_csv(
+            absolute_csv_url,
+            usecols=[
+                map_col_name_to_title[col_name]
+                for col_name in map_resource_attr_col_name_to_value_url.keys()
+            ],
+            dtype={
+                col_name: "string"
+                for col_name in map_resource_attr_col_name_to_value_url.keys()
+            },
+        )
+        return {
+            name: [
+                uritemplate.expand(value_url, {name: av})
+                for av in pandas_input_to_columnar_str(
+                    dataframe[map_col_name_to_title[name]].unique()
+                )
+            ]
+            for name, value_url in map_resource_attr_col_name_to_value_url.items()
+        }
+
+    def _map_col_title_to_attr_val_uris_and_labels(
+        self,
+        map_col_name_to_attribute_value_uris: Dict[str, List[str]],
+        map_col_name_to_title: Dict[str, str],
+    ) -> Dict[str, Dict[str, str]]:
+        """
+        Returns a dictionary of the column title mapped to a dictionary of attribute value uris and their labels
+        """
+        map_uri_to_col_name: Dict[str, str] = {
+            uri: col_name
+            for col_name, uri_list in map_col_name_to_attribute_value_uris.items()
+            for uri in uri_list
+        }
+
+        uris_to_query = list(map_uri_to_col_name.keys())
+
+        sparql_results = select_labels_for_resource_uris(
+            self.csvw_inspector.rdf_graph, uris_to_query
+        )
+
+        map_col_title_to_attr_val_uris_and_labels: Dict[str, Dict[str, str]] = {}
+        for uri, label in sparql_results.items():
+            col_name = map_uri_to_col_name[uri]
+            col_title = map_col_name_to_title[col_name]
+            results_for_col_title = map_col_title_to_attr_val_uris_and_labels.get(
+                col_title, {}
+            )
+            results_for_col_title[uri] = label
+            map_col_title_to_attr_val_uris_and_labels[col_title] = results_for_col_title
+
+        return map_col_title_to_attr_val_uris_and_labels
+
 
 def _get_column_type_and_component(
     column: ColumnDefinition,
     qube_components: List[QubeComponentResult],
     cube_shape: CubeShape,
     observations_columns: Set[ColumnDefinition],
 ) -> Tuple[EndUserColumnType, Optional[QubeComponentResult]]:
-    # We *assume* that all components which claim to be 'used' in a column express the same information about the
-    # column. i.e. if two or more components claim to be 'used' in the column, it shouldn't matter whether we pick the
-    # first or the second component, we should draw the same conclusions about the type of the column.
+    """
+    We *assume* that all components which claim to be 'used' in a column express the same information about the
+    column. i.e. if two or more components claim to be 'used' in the column, it shouldn't matter whether we pick the
+    first or the second component, we should draw the same conclusions about the type of the column.
+    """
     component_definition = first(
         qube_components, lambda q: column in q.real_columns_used_in
     )
 
     if component_definition is None:
         if column.suppress_output:
             return EndUserColumnType.Suppressed, None
```

## csvcubed/utils/sparql_handler/sparql_queries/select_is_pivoted_shape_for_measures_in_data_set.sparql

 * *Ordering differences only*

```diff
@@ -11,8 +11,8 @@
     # N.B. The join between ?dsd and ?csvUrl is injected as a `VALUES` table when the query is executed.
 
     [] csvw:url ?csvUrl;
        csvw:tableSchema/csvw:column/rdf:rest*/rdf:first [ csvw:propertyUrl ?measureColumnPropertyUrl ].
 
     BIND((STRENDS(str(?measureColumnPropertyUrl), str(?measure)) || STRENDS(str(?measure), str(?measureColumnPropertyUrl))) as ?isPivoted).
 }
-GROUP BY ?csvUrl ?measure
+GROUP BY ?csvUrl ?measure
```

## csvcubed/utils/sparql_handler/sparqlquerymanager.py

```diff
@@ -36,14 +36,15 @@
     UnitResult,
     map_catalog_metadata_results,
     map_codelists_sparql_result,
     map_column_definition_results,
     map_csvw_table_schemas_file_dependencies_result,
     map_data_set_dsd_csv_url_result,
     map_is_pivoted_shape_for_measures_in_data_set,
+    map_labels_for_resource_uris,
     map_metadata_dependency_results,
     map_primary_key_col_names_by_csv_url_result,
     map_qube_components_sparql_result,
     map_table_schema_properties_results,
     map_units,
 )
 from csvcubed.utils.sparql_handler.sparql import ask, select
@@ -84,14 +85,16 @@
 
     SELECT_IS_PIVOTED_SHAPE_FOR_MEASURES_IN_DATA_SET = (
         "select_is_pivoted_shape_for_measures_in_data_set"
     )
 
     SELECT_COLUMN_DEFINITIONS = "select_column_definitions"
 
+    SELECT_LABELS_FOR_RESOURCE_URIS = "select_labels_for_resource_uris"
+
 
 def _get_query_string_from_file(query_type: SPARQLQueryName) -> str:
     """
     Read the sparql query string from sparql file for the given query type.
 
     Member of :file:`./sparqlquerymanager.py`
 
@@ -250,14 +253,39 @@
                 URIRef(uris.dsd_uri),
             ]
             for uris in csv_dsd_dataset_uris
         ],
     )
 
 
+def _uris_to_values_binding(uris: List[str]) -> ValuesBinding:
+    return ValuesBinding(
+        variable_names=["resourceValUri"], rows=[[URIRef(uri)] for uri in uris]
+    )
+
+
+def select_labels_for_resource_uris(
+    rdf_graph: rdflib.ConjunctiveGraph, resource_uris: List[str]
+) -> Dict[str, str]:
+    """
+    Queries a list of value uris and returns associated labels
+
+    Member of :file:`./sparqlquerymanager.py`
+
+    :return: `Dict[str, str]`
+    """
+    results: List[ResultRow] = select(
+        _get_query_string_from_file(SPARQLQueryName.SELECT_LABELS_FOR_RESOURCE_URIS),
+        rdf_graph,
+        values_bindings=[_uris_to_values_binding(resource_uris)],
+    )
+
+    return map_labels_for_resource_uris(results)
+
+
 def select_dsd_code_list_and_cols(
     rdf_graph: rdflib.ConjunctiveGraph,
     json_path: Path,
 ) -> Dict[str, CodelistsResult]:
     """
     Queries code lists and columns in the data cube.
```

## csvcubed/writers/helpers/qbwriter/dsdtordfmodelshelper.py

```diff
@@ -29,15 +29,14 @@
     NewQbAttributeValue,
     QbAttribute,
     QbAttributeLiteral,
 )
 from csvcubed.models.cube.qb.components.codelist import (
     ExistingQbCodeList,
     NewQbCodeList,
-    NewQbCodeListInCsvW,
     QbCodeList,
 )
 from csvcubed.models.cube.qb.components.datastructuredefinition import (
     QbStructuralDefinition,
 )
 from csvcubed.models.cube.qb.components.dimension import (
     ExistingQbDimension,
@@ -547,16 +546,14 @@
         elif isinstance(code_list, NewQbCodeList):
             # The resource is created elsewhere. There is a separate CSV-W definition for the code-list
             return ExistingResource(
                 SkosCodeListNewResourceUriGenerator(
                     code_list, self.cube.uri_style
                 ).get_scheme_uri()
             )
-        elif isinstance(code_list, NewQbCodeListInCsvW):
-            return ExistingResource(code_list.concept_scheme_uri)
         else:
             raise TypeError(f"Unhandled codelist type {type(code_list)}")
 
     def _get_obs_val_data_type(self) -> str:
         observation_value_columns = self.cube.get_columns_of_dsd_type(
             QbObservationValue
         )
```

## csvcubed/writers/helpers/qbwriter/urihelper.py

```diff
@@ -11,15 +11,14 @@
     ExistingQbAttribute,
     NewQbAttribute,
     QbAttribute,
 )
 from csvcubed.models.cube.qb.components.codelist import (
     ExistingQbCodeList,
     NewQbCodeList,
-    NewQbCodeListInCsvW,
     QbCodeList,
 )
 from csvcubed.models.cube.qb.components.dimension import (
     ExistingQbDimension,
     NewQbDimension,
     QbDimension,
 )
@@ -341,22 +340,14 @@
             _logger.debug(
                 "valueUrl defined by new dataset-local code list %s",
                 code_list.metadata.title,
             )
             return SkosCodeListNewResourceUriGenerator(
                 code_list, self.cube.uri_style
             ).get_concept_uri(column_uri_fragment)
-        elif isinstance(code_list, NewQbCodeListInCsvW):
-            _logger.debug(
-                "valueUrl defined by legacy dataset-local code list %s",
-                code_list.concept_scheme_uri,
-            )
-            return re.sub(
-                r"\{.?notation\}", column_uri_fragment, code_list.concept_template_uri
-            )
         else:
             raise TypeError(f"Unhandled codelist type {type(code_list)}")
 
     @staticmethod
     def _get_column_uri_template_fragment(
         column: CsvColumn, escape_value: bool = False
     ) -> str:
```

## csvcubed/writers/qbwriter.py

```diff
@@ -14,18 +14,15 @@
 import pandas as pd
 
 from csvcubed.definitions import SDMX_ATTRIBUTE_UNIT_URI
 from csvcubed.models.cube.columns import CsvColumn, SuppressedCsvColumn
 from csvcubed.models.cube.cube import QbCube
 from csvcubed.models.cube.qb.columns import QbColumn
 from csvcubed.models.cube.qb.components.attribute import QbAttribute, QbAttributeLiteral
-from csvcubed.models.cube.qb.components.codelist import (
-    NewQbCodeList,
-    NewQbCodeListInCsvW,
-)
+from csvcubed.models.cube.qb.components.codelist import NewQbCodeList
 from csvcubed.models.cube.qb.components.dimension import NewQbDimension, QbDimension
 from csvcubed.models.cube.qb.components.measuresdimension import QbMultiMeasureDimension
 from csvcubed.models.cube.qb.components.observedvalue import QbObservationValue
 from csvcubed.models.cube.qb.components.unitscolumn import QbMultiUnits
 from csvcubed.utils.csvw import get_dependent_local_files
 from csvcubed.utils.file import copy_files_to_directory_with_structure
 from csvcubed.utils.qb.standardise import (
@@ -128,31 +125,14 @@
             if isinstance(code_list, NewQbCodeList):
                 _logger.debug(
                     "Writing code list %s to '%s' directory.", code_list, output_folder
                 )
 
                 code_list_writer = self._get_writer_for_code_list(code_list)
                 code_list_writer.write(output_folder)
-            elif isinstance(code_list, NewQbCodeListInCsvW):
-                # find the CSV-W codelist and all dependent relative files and copy them into the output_folder
-                _logger.debug(
-                    "Copying legacy code list %s (with dependent files) to '%s' directory.",
-                    code_list,
-                    output_folder,
-                )
-
-                dependent_files = get_dependent_local_files(
-                    code_list.schema_metadata_file_path
-                )
-                files_relative_to = code_list.schema_metadata_file_path.parent
-                copy_files_to_directory_with_structure(
-                    [code_list.schema_metadata_file_path] + list(dependent_files),
-                    files_relative_to,
-                    output_folder,
-                )
 
     def _generate_csvw_columns_for_cube(self) -> List[Dict[str, Any]]:
         columns = [self._generate_csvw_column_definition(c) for c in self.cube.columns]
         if self.cube.is_pivoted_shape:
             _logger.debug("The cube is in pivoted shape")
             columns += (
                 self._generate_virtual_columns_for_obs_vals_in_pivoted_shape_cube()
@@ -162,16 +142,15 @@
             columns += self._generate_virtual_columns_for_standard_shape_cube()
         return columns
 
     def _get_columns_for_foreign_keys(self) -> List[QbColumn[NewQbDimension]]:
         columns = []
         for col in self.cube.get_columns_of_dsd_type(NewQbDimension):
             if col.structural_definition.code_list is not None and isinstance(
-                col.structural_definition.code_list,
-                (NewQbCodeList, NewQbCodeListInCsvW),
+                col.structural_definition.code_list, NewQbCodeList
             ):
                 columns.append(col)
 
         return columns
 
     def _get_table_references_needed_for_foreign_keys(self) -> List[dict]:
         tables = []
@@ -183,29 +162,14 @@
                 tables.append(
                     {
                         "url": f"{code_list.metadata.uri_safe_identifier}.csv",
                         "tableSchema": f"{code_list.metadata.uri_safe_identifier}.table.json",
                         "suppressOutput": True,
                     }
                 )
-            elif isinstance(code_list, NewQbCodeListInCsvW):
-                _logger.debug(
-                    "Referencing legacy dataset-local code list %s with assumed table schema.",
-                    code_list,
-                )
-
-                tables.append(
-                    {
-                        "url": code_list.csv_file_relative_path_or_uri,
-                        # n.b. the below tableSchema works for *both* standard and composite legacy code lists
-                        # due to the `notation` column supporting both `Notation` *and* `URI` as column titles.
-                        "tableSchema": "https://gss-cogs.github.io/family-schemas/codelist-schema.json",
-                        "suppressOutput": True,
-                    }
-                )
             else:
                 raise TypeError(f"Unmatched codelist type {type(code_list)}")
 
         return tables
 
     def _generate_foreign_keys_for_cube(self) -> List[dict]:
         foreign_keys: List[dict] = []
@@ -223,33 +187,14 @@
                         ),
                         "reference": {
                             "resource": f"{code_list.metadata.uri_safe_identifier}.csv",
                             "columnReference": "uri_identifier",
                         },
                     }
                 )
-            elif isinstance(code_list, NewQbCodeListInCsvW):
-                _logger.debug(
-                    "Configuring foreign key constraints for legacy dataset-local code list %s",
-                    code_list,
-                )
-
-                foreign_keys.append(
-                    {
-                        "columnReference": csvw_column_name_safe(
-                            col.uri_safe_identifier
-                        ),
-                        "reference": {
-                            "resource": code_list.csv_file_relative_path_or_uri,
-                            "columnReference": "notation",
-                            # NewQbCodeListInCsvW are used for historic reasons and they always use the notation key
-                            # for their primary key. External users cannot create NewQbCodeListInCsvW.
-                        },
-                    }
-                )
             else:
                 raise TypeError(f"Unmatched codelist type {type(code_list)}")
 
         return foreign_keys
 
     def _generate_virtual_columns_for_obs_val_in_pivoted_shape_cube(
         self, obs_column: QbColumn[QbObservationValue]
```

## csvcubed/writers/skoscodelistwriter.py

```diff
@@ -28,14 +28,22 @@
 from csvcubed.writers.helpers.skoscodelistwriter.newresourceurigenerator import (
     NewResourceUriGenerator,
 )
 from csvcubed.writers.writerbase import WriterBase
 
 _logger = logging.getLogger(__name__)
 
+URI_IDENTIFIER_COL_TITLE = "Uri Identifier"
+LABEL_COL_TITLE = "Label"
+NOTATION_COL_TITLE = "Notation"
+PARENT_URI_IDENTIFIER_COL_TITLE = "Parent Uri Identifier"
+SORT_PRIORITY_COL_TITLE = "Sort Priority"
+DESCRIPTION_COL_TITLE = "Description"
+ORIGINAL_CONCEPT_URI_COL_TITLE = "Original Concept URI"
+
 
 @dataclass
 class SkosCodeListWriter(WriterBase):
     new_code_list: NewQbCodeList
     default_uri_style: URIStyle = URIStyle.Standard
     csv_file_name: str = field(init=False)
     uri_helper: NewResourceUriGenerator = field(init=False)
```

## Comparing `csvcubed-0.3.5.dist-info/LICENSE` & `csvcubed-0.3.6.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `csvcubed-0.3.5.dist-info/METADATA` & `csvcubed-0.3.6.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: csvcubed
-Version: 0.3.5
+Version: 0.3.6
 Summary: A tool to generate RDF Data Cube style CSV-W cubes from tidy CSV files. Part of the csvcubed family.
 License: Apache-2.0
 Author: Integrated Data Service - Dissemination
 Author-email: csvcubed@gsscogs.uk
 Requires-Python: >=3.9,<3.12
 Classifier: License :: OSI Approved :: Apache Software License
 Classifier: Programming Language :: Python :: 3
```

## Comparing `csvcubed-0.3.5.dist-info/RECORD` & `csvcubed-0.3.6.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -19,23 +19,23 @@
 csvcubed/models/csvcubedexception.py,sha256=cfE3N-06CZ_bjMJV5gZ4KK6JLuFdq7Jcbe4uZiA-Krc,14542
 csvcubed/models/csvwtype.py,sha256=7WXT5EcWT48YNFn3oyPJkgPKRDPoyJZZrXHvaeWC6Jk,409
 csvcubed/models/cube/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/models/cube/catalog.py,sha256=9AX4wIIglrjSTkhUI2YmzbLv_D9Z4rmz11bTMN74occ,676
 csvcubed/models/cube/columns.py,sha256=Abm4LtHqIy1Xa1HWiZfSXluCpETcVIYkwhdkLORUVe8,1367
 csvcubed/models/cube/cube.py,sha256=yf8MhAfUzCgF1aUIwL83cJO69QbGyyR8Z8D0gaD8R28,7486
 csvcubed/models/cube/cube_shape.py,sha256=rKamnT0oyVesazKlQnCt2jYMHVeCIoG6kc3H34bTlms,234
-csvcubed/models/cube/qb/README.md,sha256=_CYBbn7WJdU14Fqp9D5FKaZrPuqsUh7IGnp9RuLXePA,13230
+csvcubed/models/cube/qb/README.md,sha256=i3jw181rEUdhlPO66pswRAUGpG3ZhB7af4RY6oE87OE,13122
 csvcubed/models/cube/qb/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/models/cube/qb/catalog.py,sha256=GDeGA2vAhxxv73d1fKyPEZEsjRtaN2b6lY0GcsttnpA,4224
 csvcubed/models/cube/qb/columns.py,sha256=5hCyw91tpLicIgSG8cTlcuXrrxIQXvi7Fx2jpsFMZjs,2430
 csvcubed/models/cube/qb/components/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/models/cube/qb/components/arbitraryrdf.py,sha256=6M9tN1B5OCKpLhvCZPrjeyaqslHZNZ_O7ndZL-trak8,7192
 csvcubed/models/cube/qb/components/attribute.py,sha256=4jv6cBSmjdT7FNvwiTaREFZf4-zflYVCcsE6r7hiz98,11530
 csvcubed/models/cube/qb/components/attributevalue.py,sha256=boe5Sep_w5hRZX3S05CQQbeQINB4hDxOWk_BfYkXwC4,1832
-csvcubed/models/cube/qb/components/codelist.py,sha256=X5tQHAytRTut8q5CigN0vRYA6RiOLB_qXFRYAjr8c5k,7728
+csvcubed/models/cube/qb/components/codelist.py,sha256=n7o6xZ8KcKQtnI3Flhs3wLey9ewCBCokF8KgwuX5_f4,5188
 csvcubed/models/cube/qb/components/concept.py,sha256=WN_t17CLVkoG3TcG1C8_rlotusOeJIu_SQphrYfgbbU,2377
 csvcubed/models/cube/qb/components/constants.py,sha256=GvJrop1yq7JF1sby0foyQ0djbb0m96QvWz2mUb0gvyo,1052
 csvcubed/models/cube/qb/components/datastructuredefinition.py,sha256=rA5uruWAT-5Uj0VvlwUHiaq1ofvYHRUZ18N6vLBALLw,1370
 csvcubed/models/cube/qb/components/dimension.py,sha256=jW0VSyUxhmVQ1ZfLZXrqjVjR8i2KFlPwlaW32UEezyk,5431
 csvcubed/models/cube/qb/components/measure.py,sha256=O8cwVLkrZzdwCixqnst-Kw_U42mjc20Jw6J35xVuTOE,3419
 csvcubed/models/cube/qb/components/measuresdimension.py,sha256=Xs2xxeaZ-Nr97TQmfXaEY-Kty2aYfEyFtbeCegZGYrM,4284
 csvcubed/models/cube/qb/components/observedvalue.py,sha256=C8-QO3eD952bDSjbZ3mZVlZ3f2WCpfAT2ZVcWDX9HtU,1598
@@ -52,28 +52,28 @@
 csvcubed/models/rdf/conceptschemeincatalog.py,sha256=p3e1CLP9c5qcGw3hhl8H_N6Y1VJW8K-wgvz4D75XYks,526
 csvcubed/models/rdf/newattributevalueresource.py,sha256=QJ2fWjQ_VuOVQFWDAD7N4Xhf4nzhp4q9A1BVTsJ_1Yo,858
 csvcubed/models/rdf/newunitresource.py,sha256=6vr5T8UGXrqjG6AINYcNcGsC1LMjt-eNO25jF8J3P9Q,1670
 csvcubed/models/rdf/prov.py,sha256=BzvPmYiKv1nOC0unrBg8lYu5pXemDz3syQLaQX62rIA,1188
 csvcubed/models/rdf/qbdatasetincatalog.py,sha256=IpRZBm6JWkfRzrlgSnl5n8IjRccb0_eOkNS9Hf-luTU,447
 csvcubed/models/sparql/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/models/sparql/valuesbinding.py,sha256=nJxVQgytQZrYrnCPssr_-EMO7uY2rpGxaNLwy9MTfLo,457
-csvcubed/models/sparqlresults.py,sha256=bKulYEw_N2E4IumOT6yZnXpHCLjMs6OiC-UO6OTQg58,19449
+csvcubed/models/sparqlresults.py,sha256=_Wvvzcg7Y6jlbfFj0TJGky9yaQb46Qw4AuJgZsTLIbY,20070
 csvcubed/models/uriidentifiable.py,sha256=tP9hBDJj7LIUMjdvO7mc2PYNKOCmu8NjSt_2XFtpIFw,1814
 csvcubed/models/validatedmodel.py,sha256=IcRFWUvmXO839gU1HCLQ8h41_CGqkdSe8mfBD2uvD9Q,3108
 csvcubed/models/validationerror.py,sha256=uDx5TPS_VcZZT790HM_V_hlkKnRj19-YIJrBIJnfrEY,3167
 csvcubed/readers/__init__.py,sha256=j-b06j5EDS5IAqkd7FkyGb9TV-KLDyGB0_g65LnaoEA,110
 csvcubed/readers/catalogmetadata/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/readers/catalogmetadata/v1/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/readers/catalogmetadata/v1/catalog_metadata_reader.py,sha256=BqmMn8wEc5KCcAhtCkXfNr78BZe6bRvKAywQ5m_gMgY,1637
 csvcubed/readers/codelistconfig/codelist_schema_versions.py,sha256=tbCSAiFKIHPdgOQeAL2DxCnETllJZ2RYXAO0YAznVbg,6719
 csvcubed/readers/cubeconfig/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/readers/cubeconfig/schema_versions.py,sha256=DRtWlYhy6QbBJyrmfdtIVhvDuvceujjLC5-F85wG9aY,4878
 csvcubed/readers/cubeconfig/utils.py,sha256=CCq1Fu5SbGPSi02MPLsR-08tje0ByK5wc3xw5_esRGc,1814
 csvcubed/readers/cubeconfig/v1/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-csvcubed/readers/cubeconfig/v1/columnschema.py,sha256=45RJLKx_e7B3VN-j79ILPDxe2sbPOLggpuOvqZzPfOY,18797
+csvcubed/readers/cubeconfig/v1/columnschema.py,sha256=FwscYOfjSs-uyH0XwdxvfG9Drqq_fRP_aDxiGDh3ktc,20171
 csvcubed/readers/cubeconfig/v1/configdeserialiser.py,sha256=QstbhGGcOrbSHnC8YJe4ZzUdK9rDx8xzla4mZGTedfQ,14157
 csvcubed/readers/cubeconfig/v1/constants.py,sha256=gUVnAVgrNF3HLlBn4MuEYPsIcDsD_Tjt5-GOSHyPtpE,629
 csvcubed/readers/cubeconfig/v1/datatypes.py,sha256=ORpESm5zGMUjLa78MZzxNUeSqj75DxPz5jeeoiGkeLo,4071
 csvcubed/readers/cubeconfig/v1/mapcolumntocomponent.py,sha256=Pkx0sPoNg7o4WOELVPBNkwd5y-b26Idyjjzc0VloQks,9137
 csvcubed/readers/cubeconfig/v1_0/readme.md,sha256=PlZMtxW93oA89UzwpvukvgpdB9bKoTz-EzDf4bk6I3M,182
 csvcubed/readers/cubeconfig/v1_0/templates/README.md,sha256=7o-Osoki8FBzRiU9sdTAfBlf5S1GUsbInHubMZKpaaI,911
 csvcubed/readers/cubeconfig/v1_0/templates/calendar-day.json,sha256=oXr64AxuPOMSOMYTGDTY432C8t3vCEq8mBUpFPYeoSM,210
@@ -93,15 +93,14 @@
 csvcubed/readers/cubeconfig/v1_0/templates/gregorian-interval.json,sha256=ihhKRmq_E6Gi0W2vXeJWMiMujKaU_QRPjvbhEbMrpyE,246
 csvcubed/readers/cubeconfig/v1_0/templates/mixed-period.json,sha256=dqpS-QJssrush8vyteqG7ciQUnaXNymn4E-zQkKFuZ8,345
 csvcubed/readers/cubeconfig/v1_0/templates/observation-status.json,sha256=Xfv63Q9Ssxjs8mrkCr8XXVd-XEXowXodEMx4IQu29yQ,144
 csvcubed/readers/cubeconfig/v1_0/templates/preset_column_config.json,sha256=eCm3uwehDw-TFKI2D_ugpWoZ97vWU0oVOBrVjO-F2BM,826
 csvcubed/readers/cubeconfig/v1_0/templates/qudt-units.json,sha256=-lQlgBb_UyivCva9E1kSZMq8TqBRmgTMlbFXu_25k3s,95
 csvcubed/readers/cubeconfig/v1_0/templates/statistical-geography.json,sha256=wRReh4FU_28Bl09JJ-VIKOUcZgfRYGXL3k_RetblVIw,270
 csvcubed/readers/preconfiguredtemplates.py,sha256=CL8wTOdSmf375Dm-nhvxEqokNmRX8-CE4tqko779TXU,3942
-csvcubed/readers/skoscodelistreader.py,sha256=SY_nq4Xq1sUs6-tEBtqobwFJ3cIHSxOmJtq7zGH2T8g,2267
 csvcubed/schema/codelist-config/v1_0/codelistconfig-example.jsonc,sha256=zZUZAVxewdxpRt5e_jF6UzrGsIZ7cxzxqPctuAMCRyU,1647
 csvcubed/schema/codelist-config/v1_0/schema.json,sha256=SoCAdfcZO9439MAFjF_BYp2P96eF8n1K03I7BYj9dpg,4941
 csvcubed/schema/codelist-config/v1_1/schema.json,sha256=YvxsuNZjk8SWokh6aUpifABYFiDi6TmbNiqrl8S6mrM,6597
 csvcubed/schema/cube-config/v1_0/qbconfig-example.jsonc,sha256=UgF3Yn7oybxWF4pYnNr-o78uBRMIqbwQG1yfRCsm6Nc,11497
 csvcubed/schema/cube-config/v1_0/schema.json,sha256=j6WWPxsgLsm8MriX61-KfZmxakji91HsilAi5SQQwKE,23488
 csvcubed/schema/cube-config/v1_1/qbconfig-example.jsonc,sha256=dpmKT0QeJOs-QntgUGHGr23lgqIEj93gpWa8NkUNlfo,11153
 csvcubed/schema/cube-config/v1_1/schema.json,sha256=SfM5ceL8lxeouVyko03CB09sIfydh9qqH0DMqKT7J28,25257
@@ -115,66 +114,67 @@
 csvcubed/utils/csvdataset.py,sha256=X3aVbVESjLoOUxpDSbREQg0sQxjXviaq-cJqqr3sjbY,14033
 csvcubed/utils/csvw.py,sha256=SIzMCURqDOnlCU_oHmSsyturOw2-ecA0QAsT4sicujw,4518
 csvcubed/utils/datetime.py,sha256=VaammJPt10PUuN4qGgsntobgbCKUOIoqNNEwpDHWtRA,453
 csvcubed/utils/dict.py,sha256=YlhEoyBELSrKcS0dd42b7SMBSHX7Eh0R1uV4cabXU8M,1488
 csvcubed/utils/file.py,sha256=9q_7i8MPriBdggvHCFIY2VYgeoiFru4kGyWWJ2Nb9F0,1682
 csvcubed/utils/iterables.py,sha256=cP-wcLYUj-M1QNc9ysnt7l_ILYPd-nMY9IzXPqG4WDA,1582
 csvcubed/utils/json.py,sha256=qg29-TkmSa9myqz1SHi6mUTsKCNCsmCx4Z4hmHLw9gs,4253
-csvcubed/utils/log.py,sha256=t3Oj5LW1GhqhRVxaRop4yDLbzfGMNJokRMCzQZr4HDY,3395
-csvcubed/utils/pandas.py,sha256=we3IgVccsrEndvQ6hgxpLmVXcfFUgcvPm4ki2CSesAI,1556
+csvcubed/utils/log.py,sha256=3dAi3C5CcDBzYFuhlHANoi-I0HmNUYbTfobGFp9pWtw,3333
+csvcubed/utils/pandas.py,sha256=BSgdW897rJf5jgv4KvFggTmKa0qnRkoHazB7lstnQ-4,1783
 csvcubed/utils/printable.py,sha256=n_gY1VHZ71I0aMNzC9xaUtIFexxtdJXTNTw9DLdiLFI,1169
 csvcubed/utils/qb/__init__.py,sha256=co8SgYAU9PKQALalcvK4Ty96h0zLeGQ3Xf0UUMUd6tQ,41
 csvcubed/utils/qb/components.py,sha256=tFBtLHzhp9Rn1CnwLstgPzvBlLPOlNQy-PA6c7TMzjo,4228
 csvcubed/utils/qb/cube.py,sha256=NBPI1keSiGIUrg9dLADqNfSkSlrb5LFlcASCsDnrkxE,3512
 csvcubed/utils/qb/standardise.py,sha256=SZegTL5FE0JZsuZQRLwO8BmcjT7bwI5MMWCUNJ9h0Mc,8509
 csvcubed/utils/qb/validation/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/utils/qb/validation/cube.py,sha256=uZMkkEaRIrJw3HZxyZtQs9XFs1cMD7KQlSccvJuv12Y,2983
 csvcubed/utils/qb/validation/observations.py,sha256=Ubv0vTfdHkcmRQ9mE21Eb8I0xEu239zxEhC3D505aWM,18273
 csvcubed/utils/qb/validation/uri_safe.py,sha256=lgnkxSplAT1E5QUWAOD8i4pe2u3JneLEBa9N2th0AQQ,1672
 csvcubed/utils/rdf.py,sha256=Ki0Sqh0FWB6atz4q2xtbDcgQVDLcb00PuRkWuo5WJnk,1945
 csvcubed/utils/skos/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/utils/skos/codelist.py,sha256=nIENnG8nm-jEBnO05Ge-rWEItXLYDVmUey2qIvhe0bI,3017
 csvcubed/utils/sparql_handler/__init__.py,sha256=IUbRkPhSFfbFNEt0Jsht80tOyjmuWfEAlpCDHH6mUp8,89
-csvcubed/utils/sparql_handler/code_list_inspector.py,sha256=0TZXu5gmnUWKSHH1T4zR2gmB0HP_gitla3UAUECi-po,4121
+csvcubed/utils/sparql_handler/code_list_inspector.py,sha256=SF_cQlkPLkBN27bJ7rOE9D14gf7-HKGGo9W8qG8KBvI,6289
 csvcubed/utils/sparql_handler/column_component_info.py,sha256=E5OrqZcxppALLqTMDyC8tEtA_4s0D3XyncMKIT3x18E,955
 csvcubed/utils/sparql_handler/csvw_inspector.py,sha256=rGJY6k4AzGWrz_7EiJquHbmhFdLRYNfx3l7qLKtnSrM,4583
-csvcubed/utils/sparql_handler/data_cube_inspector.py,sha256=2nYbX93KdtJx5ycKIm9w60jbFryjzBL5H0Yp2o9B35k,13992
+csvcubed/utils/sparql_handler/data_cube_inspector.py,sha256=THramrYQtlAVvmiDd6L4Xxlvo-Yzrq10Ne4EL6t_mms,18992
 csvcubed/utils/sparql_handler/sparql.py,sha256=t2rK3MztIy0JTbASmpxNfKBMCa0lZ-EAUn4CnLVxsWA,3889
 csvcubed/utils/sparql_handler/sparql_queries/ask_is_codelist.sparql,sha256=9_qf61Mn1b4H2huNFvhxDD78jTqWw7W2Zrk0g6msino,88
 csvcubed/utils/sparql_handler/sparql_queries/ask_is_qb_dataset.sparql,sha256=eYgoKHTGTaex3xizQ9lx5t9kEPu6ejvXC7El8M2aXSk,75
 csvcubed/utils/sparql_handler/sparql_queries/select_catalog_metadata.sparql,sha256=HSF4DAB79RvFMU6zWHXvQjEcvfZ8ivtUolMxUyFIsCo,2298
 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_csv_url.sparql,sha256=LEFLJBati_-bGkBnnJEG7XgA5VYhiMm9kdB9gW7e3H8,1006
 csvcubed/utils/sparql_handler/sparql_queries/select_codelist_primary_key_by_csv_url.sparql,sha256=JLs1SHwPrTBsV45COO9gOk2hj4Z4vjSi4uBE2GFrsis,482
 csvcubed/utils/sparql_handler/sparql_queries/select_codelists_and_cols.sparql,sha256=oGxWovWaoGcyB-Ez8eM7oECscpaP1BiDbLWeSJxb-vw,969
 csvcubed/utils/sparql_handler/sparql_queries/select_column_definitions.sparql,sha256=3SKgOc4N8uexKI93DUivW05NZJSYw4gcDQVyaUJlB9g,2149
 csvcubed/utils/sparql_handler/sparql_queries/select_csvw_table_schema_file_dependencies.sparql,sha256=qk0zSe5baKHfXM9-IXk_0xY3KMog3ED1-7_p-sDSezA,354
 csvcubed/utils/sparql_handler/sparql_queries/select_data_set_dsd_csv_url.sparql,sha256=VuGw9y_aKTP3G59PUlUh_-wj7bfHILQnH2XajOJTcvM,1188
 csvcubed/utils/sparql_handler/sparql_queries/select_dsd_qube_components.sparql,sha256=_5LF2eWp_udc09q-U2F0ZwMHIxWwliF8tkKOgYGyXNw,1339
-csvcubed/utils/sparql_handler/sparql_queries/select_is_pivoted_shape_for_measures_in_data_set.sparql,sha256=nnYB-BR1_-KvdFZ-bS0eROXTsJKfBfwbnu-sWI9bkwo,756
+csvcubed/utils/sparql_handler/sparql_queries/select_is_pivoted_shape_for_measures_in_data_set.sparql,sha256=HAKnXxouSVGIue0V_1YPHCMMcFR9lTxhxS-ljP0jMLY,757
+csvcubed/utils/sparql_handler/sparql_queries/select_labels_for_resource_uris.sparql,sha256=R0e2hBvyTggTJW3iyRubeOsLomLlyoP_q_m6wi12dEM,179
 csvcubed/utils/sparql_handler/sparql_queries/select_metadata_dependencies.sparql,sha256=rmCH3---NlDNQXu1hlq-fvvMIAckNYkHZPe3tdlXdLU,379
 csvcubed/utils/sparql_handler/sparql_queries/select_table_schema_properties.sparql,sha256=2al7ZhCLHtPEVkvubzigAlmrTuT5AHup5B6WtoQxzBw,466
 csvcubed/utils/sparql_handler/sparql_queries/select_units.sparql,sha256=uuA1L0fywz9oosVyGd3WIKCILBi1KvYlZqfj519rmQE,367
-csvcubed/utils/sparql_handler/sparqlquerymanager.py,sha256=x6Dz_PMF390uY5bdrF4l1Z_wiHQam52KZqGXJzSYiyY,10794
+csvcubed/utils/sparql_handler/sparqlquerymanager.py,sha256=f_H6c8ryd5uh-lcyeDPhMlE5VlrxL6-UMpWRvHecNfo,11626
 csvcubed/utils/tableschema.py,sha256=erd6PZ9l3fLRTXv-L9NwnU5DmxJPO7nhivf7bOb0m_I,8831
 csvcubed/utils/text.py,sha256=bIj2Ykra-bXaUk-EyrYCy07LrHZdY6dYXsYO8A6I_i0,356
 csvcubed/utils/uri.py,sha256=ZEX3IQG0r_xV4W_p4omhKs6x8YdXLnOGxa8vmwH_r4o,3467
 csvcubed/utils/validations.py,sha256=uWuLPturZRk6p59ya-U_zymGZBC4tM0MdGbeaGy7IE0,11239
 csvcubed/utils/validators/__init__.py,sha256=fHGeu6xOpC030v5SM2wzkvnKad8uC8_LavMJU5UxKho,45
 csvcubed/utils/validators/schema.py,sha256=txW2VLdGv1-Wo15aTgWjEiGLM3Jac1T4iU0k7eIifIc,4360
 csvcubed/utils/version.py,sha256=T-I5rVx5T08tqrTNldwwDYQVzarYtwQ_ap0g8JbgTbw,268
 csvcubed/writers/__init__.py,sha256=njopI6UIMFsqWF6i5v5huPhvRvixU-creIptscLQBUg,62
 csvcubed/writers/helpers/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/writers/helpers/qbwriter/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-csvcubed/writers/helpers/qbwriter/dsdtordfmodelshelper.py,sha256=BGCJjPDVnQY7lmg238k_BwQoBMT2tGL-3JqAjY_Sc-4,23100
+csvcubed/writers/helpers/qbwriter/dsdtordfmodelshelper.py,sha256=3hVEeqJ_txmCO7yOnLkOqCWtQB5tRRP1no80p3zAyv4,22952
 csvcubed/writers/helpers/qbwriter/newresourceurigenerator.py,sha256=yuwI8enmByK3xNFQ6c8v7q2kxJ5Bv4hPA3uiTja2Jw0,3597
-csvcubed/writers/helpers/qbwriter/urihelper.py,sha256=fZC5iBlM_GbZZOniaVTdFfzbVKPbalC8cymeuaFxDdM,27748
+csvcubed/writers/helpers/qbwriter/urihelper.py,sha256=BzVnUueyoE1DBncTByKnigeLozePdfFRfxzaguwCtxY,27378
 csvcubed/writers/helpers/skoscodelistwriter/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 csvcubed/writers/helpers/skoscodelistwriter/constants.py,sha256=FjVa2JsAc7uIxzQOJgNg3zf8Ha-YZvMzF75sqq_e93g,157
 csvcubed/writers/helpers/skoscodelistwriter/newresourceurigenerator.py,sha256=DWkL2zO4QsLV8Oo-nVXxS4cxA1ic4stSBp7NZpClbps,2437
-csvcubed/writers/qbwriter.py,sha256=WHJRXW0z2Fv4Uzc-9nt-hgzh2845UOUVzKndNqPEpec,23393
-csvcubed/writers/skoscodelistwriter.py,sha256=4Y4-bmrbb1vHham49M_uTNUrc5W7by3V1Lkjlmpsz5U,9173
+csvcubed/writers/qbwriter.py,sha256=fDesUmhWU1211z_wDQi8xFdfpB0CqdSHG7pM-YlsJQc,20804
+csvcubed/writers/skoscodelistwriter.py,sha256=dCK3RaOrv4jeD6l4SZ2PT9tr8zqZwR2x8kbRTsASIMc,9470
 csvcubed/writers/writerbase.py,sha256=lzEHMgqdWBIFbxthYjf5JuE3i5gp5Vbb1Xw359TY3to,283
-csvcubed-0.3.5.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-csvcubed-0.3.5.dist-info/WHEEL,sha256=vVCvjcmxuUltf8cYhJ0sJMRDLr1XsPuxEId8YDzbyCY,88
-csvcubed-0.3.5.dist-info/entry_points.txt,sha256=sGis93BsSIrPNIht5YkyuYCvefbri5nvVdOyI9ImAFs,64
-csvcubed-0.3.5.dist-info/METADATA,sha256=ALaqCX0qMgSq2apcR2cgga2o5SLbevY9J8Ke1bdS2mE,3925
-csvcubed-0.3.5.dist-info/RECORD,,
+csvcubed-0.3.6.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+csvcubed-0.3.6.dist-info/METADATA,sha256=k_XMVhEwfA1lVEzLxuOvEyrfXBdRqWI-mrxjcwbqIR4,3925
+csvcubed-0.3.6.dist-info/WHEEL,sha256=7Z8_27uaHI_UZAc4Uox4PpBhQ9Y5_modZXWMxtUi4NU,88
+csvcubed-0.3.6.dist-info/entry_points.txt,sha256=sGis93BsSIrPNIht5YkyuYCvefbri5nvVdOyI9ImAFs,64
+csvcubed-0.3.6.dist-info/RECORD,,
```

