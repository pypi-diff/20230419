# Comparing `tmp/sparclclient-1.2.0b3.dev7-py3-none-any.whl.zip` & `tmp/sparclclient-1.2.0b3.dev8-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,21 +1,19 @@
-Zip file size: 29954 bytes, number of entries: 19
--rw-rw-r--  2.0 unx     7061 b- defN 23-Feb-28 20:09 sparcl/Results.py
--rw-rw-r--  2.0 unx     1018 b- defN 23-Mar-26 21:31 sparcl/__init__.py
--rw-rw-r--  2.0 unx      798 b- defN 23-Mar-15 14:12 sparcl/big_retrieve.py
--rw-rw-r--  2.0 unx    29594 b- defN 23-Mar-26 21:15 sparcl/client.py
--rw-rw-r--  2.0 unx      953 b- defN 23-Feb-08 18:38 sparcl/conf.py
--rw-rw-r--  2.0 unx      887 b- defN 23-Mar-15 15:44 sparcl/dls_376.py
--rw-rw-r--  2.0 unx     3812 b- defN 23-Mar-01 23:05 sparcl/exceptions.py
--rw-rw-r--  2.0 unx     5002 b- defN 23-Mar-26 21:24 sparcl/fields.py
--rw-rw-r--  2.0 unx     6781 b- defN 23-Feb-28 20:09 sparcl/gather_2d.py
--rw-rw-r--  2.0 unx    13112 b- defN 23-Feb-08 18:38 sparcl/type_conversion.py
--rw-rw-r--  2.0 unx     1867 b- defN 23-Feb-28 20:09 sparcl/unsupported.py
--rw-rw-r--  2.0 unx     4682 b- defN 23-Mar-26 21:03 sparcl/utils.py
--rw-rw-r--  2.0 unx        0 b- defN 23-Feb-08 18:38 sparcl/benchmarks/__init__.py
--rw-rw-r--  2.0 unx     9667 b- defN 23-Feb-08 18:38 sparcl/benchmarks/benchmarks.py
--rw-rw-r--  2.0 unx     1576 b- defN 23-Mar-26 21:33 sparclclient-1.2.0b3.dev7.dist-info/LICENSE
--rw-rw-r--  2.0 unx      872 b- defN 23-Mar-26 21:33 sparclclient-1.2.0b3.dev7.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Mar-26 21:33 sparclclient-1.2.0b3.dev7.dist-info/WHEEL
--rw-rw-r--  2.0 unx        7 b- defN 23-Mar-26 21:33 sparclclient-1.2.0b3.dev7.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     1518 b- defN 23-Mar-26 21:33 sparclclient-1.2.0b3.dev7.dist-info/RECORD
-19 files, 89299 bytes uncompressed, 27490 bytes compressed:  69.2%
+Zip file size: 28607 bytes, number of entries: 17
+-rw-rw-r--  2.0 unx     8000 b- defN 23-Apr-19 01:23 sparcl/Results.py
+-rw-rw-r--  2.0 unx     1018 b- defN 23-Apr-19 21:21 sparcl/__init__.py
+-rw-rw-r--  2.0 unx    29299 b- defN 23-Apr-19 21:11 sparcl/client.py
+-rw-rw-r--  2.0 unx      953 b- defN 22-Aug-23 21:07 sparcl/conf.py
+-rw-rw-r--  2.0 unx     3813 b- defN 23-Apr-19 01:21 sparcl/exceptions.py
+-rw-rw-r--  2.0 unx     4949 b- defN 23-Feb-07 18:10 sparcl/fields.py
+-rw-rw-r--  2.0 unx     6781 b- defN 23-Feb-08 21:54 sparcl/gather_2d.py
+-rw-rw-r--  2.0 unx    13112 b- defN 22-Sep-14 20:31 sparcl/type_conversion.py
+-rw-rw-r--  2.0 unx     1867 b- defN 23-Feb-08 21:54 sparcl/unsupported.py
+-rw-rw-r--  2.0 unx     3965 b- defN 22-Aug-23 21:07 sparcl/utils.py
+-rw-rw-r--  2.0 unx        0 b- defN 22-Aug-23 21:07 sparcl/benchmarks/__init__.py
+-rw-rw-r--  2.0 unx     9667 b- defN 22-Nov-02 21:04 sparcl/benchmarks/benchmarks.py
+-rw-r--r--  2.0 unx     1576 b- defN 23-Apr-19 21:23 sparclclient-1.2.0b3.dev8.dist-info/LICENSE
+-rw-rw-r--  2.0 unx      872 b- defN 23-Apr-19 21:23 sparclclient-1.2.0b3.dev8.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-19 21:23 sparclclient-1.2.0b3.dev8.dist-info/WHEEL
+-rw-rw-r--  2.0 unx        7 b- defN 23-Apr-19 21:23 sparclclient-1.2.0b3.dev8.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1367 b- defN 23-Apr-19 21:23 sparclclient-1.2.0b3.dev8.dist-info/RECORD
+17 files, 87338 bytes uncompressed, 26373 bytes compressed:  69.8%
```

## zipnote {}

```diff
@@ -1,25 +1,19 @@
 Filename: sparcl/Results.py
 Comment: 
 
 Filename: sparcl/__init__.py
 Comment: 
 
-Filename: sparcl/big_retrieve.py
-Comment: 
-
 Filename: sparcl/client.py
 Comment: 
 
 Filename: sparcl/conf.py
 Comment: 
 
-Filename: sparcl/dls_376.py
-Comment: 
-
 Filename: sparcl/exceptions.py
 Comment: 
 
 Filename: sparcl/fields.py
 Comment: 
 
 Filename: sparcl/gather_2d.py
@@ -36,23 +30,23 @@
 
 Filename: sparcl/benchmarks/__init__.py
 Comment: 
 
 Filename: sparcl/benchmarks/benchmarks.py
 Comment: 
 
-Filename: sparclclient-1.2.0b3.dev7.dist-info/LICENSE
+Filename: sparclclient-1.2.0b3.dev8.dist-info/LICENSE
 Comment: 
 
-Filename: sparclclient-1.2.0b3.dev7.dist-info/METADATA
+Filename: sparclclient-1.2.0b3.dev8.dist-info/METADATA
 Comment: 
 
-Filename: sparclclient-1.2.0b3.dev7.dist-info/WHEEL
+Filename: sparclclient-1.2.0b3.dev8.dist-info/WHEEL
 Comment: 
 
-Filename: sparclclient-1.2.0b3.dev7.dist-info/top_level.txt
+Filename: sparclclient-1.2.0b3.dev8.dist-info/top_level.txt
 Comment: 
 
-Filename: sparclclient-1.2.0b3.dev7.dist-info/RECORD
+Filename: sparclclient-1.2.0b3.dev8.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## sparcl/Results.py

```diff
@@ -76,42 +76,65 @@
                 if new == '_dr':
                     # keep DR around unchanged. We need it to rename back
                     # to Internal Field Names later.
                     continue
                 new = self.fields._internal_name(new, dr)
                 rec[new] = rec.pop(new)
 
+    def science_to_internal_fields(self):
+        newrecs = list()
+        for rec in self.recs:
+            newrec = dict()
+            dr = rec['_dr']
+            keep = True
+            for sci_name in rec.keys():
+                if sci_name == '_dr':
+                    # keep DR around unchanged. We need it to rename back
+                    # to Internal Field Names later.
+                    newrec[sci_name] = rec[sci_name]
+                else:
+                    new = self.fields._internal_name(sci_name, dr)
+                    if new is None:
+                        keep = False
+                    newrec[new] = rec[sci_name]
+            if keep:
+                newrecs.append(_AttrDict(newrec))
+        self.recs = newrecs
+        return self.recs
+
     def reorder(self, ids_og):
         """
         Reorder the retrieved records to be in the same
         order as the original IDs passed to client.retrieve().
 
         Args:
-            ids_og (:obj:`list`): List of UUIDs.
+            ids_og (:obj:`list`): List of sparcl_ids or specIDs.
 
         Returns:
             reordered (:class:`~sparcl.Results.Retrieved`): Contains header and
                                                             reordered records.
             # none_idx (:obj:`list`): List of indices where record is None.
 
         """
         if len(ids_og) <= 0:
             msg = (f'The list of IDs passed to the reorder method '
-                   f'does not contain any IDs or specIDs.')
+                   f'does not contain any sparcl_ids or specIDs.')
             raise ex.NoIDs(msg)
         elif len(self.recs) <= 0:
             msg = (f'The retrieved or found results did not '
                    f'contain any records.')
             raise ex.NoRecords(msg)
         else:
+            # Transform science fields to internal fields
+            new_recs = self.science_to_internal_fields()
             # Get the ids or specids from retrieved records
             if type(ids_og[0]) == str:
-                ids_re = [f['id'] for f in self.recs]
+                ids_re = [f['id'] for f in new_recs]
             elif type(ids_og[0]) == int:
-                ids_re = [f['specid'] for f in self.recs]
+                ids_re = [f['specid'] for f in new_recs]
             # Enumerate the original ids
             dict_og = {x: i for i, x in enumerate(ids_og)}
             # Enumerate the retrieved ids
             dict_re = {x: i for i, x in enumerate(ids_re)}
             # Get the indices of the original ids. Set to None if not found
             idx = [dict_re.get(key, None) for key in dict_og.keys()]
             # Get the indices of None values
@@ -122,26 +145,26 @@
             dummy_record = "{'id': None, 'specid': None, '_dr': 'SDSS-DR16'}"
             for i in none_idx:
                 reordered.insert(i, {'id': None, 'specid': None,
                                      '_dr': 'SDSS-DR16'})
             reordered.insert(0, self.hdr)
             meta = reordered[0]
             if len(none_idx) > 0:
-                msg = (f'{len(none_idx)} IDs or specIDs were not found in '
+                msg = (f'{len(none_idx)} sparcl_ids or specIDs were '
+                       f'not found in '
                        f'the database. Use "client.missing()" '
                        f'to get a list of the unavailable IDs. '
                        f'To maintain correct reordering, a dummy '
                        f'record has been placed at the indices '
                        f'where no record was found. Those '
                        f'indices are: {none_idx}. The dummy '
                        f'record will appear as follows: '
                        f'{dummy_record}. ')
                 meta['status'].update({'warnings': [msg]})
                 warn(msg, stacklevel=2)
-
         return Results(reordered, client=self.client)
 
 
 # For results of retrieve()
 class Retrieved(Results):
     """Holds spectra records (and header)."""
```

## sparcl/__init__.py

```diff
@@ -27,8 +27,8 @@
 #__version__ = '1.0.0b1.dev7'
 #__version__ = '1.0.0b1.dev8'
 #__version__ = '1.0.0b1.dev9'
 #__version__ = '1.0.1b2.dev1'
 #__version__ = '1.1rc1'
 #__version__ = '1.1rc2'
 #__version__ = '1.1'
-__version__ = '1.2.0b3.dev7'
+__version__ = '1.2.0b3.dev8'
```

## sparcl/client.py

```diff
@@ -2,14 +2,15 @@
 This module interfaces to the SPARC-Server to get spectra data.
 """
 # python -m unittest tests.tests_api
 #
 # Doctest example:
 #   cd ~/sandbox/sparclclient
 #   activate
+#   pip install -e .
 #   python sparcl/client.py
 #   ## Returns NOTHING if everything works, else lists errors.
 
 ############################################
 # Python Standard Library
 from urllib.parse import urlencode, urlparse
 from warnings import warn
@@ -246,15 +247,15 @@
         Returns:
             List of fields tagged as 'all' from DATASET_LIST.
 
         Example:
             >>> client = SparclClient()
             >>> client.get_all_fields()
             ['data_release', 'datasetgroup', 'dateobs', 'dateobs_center', 'dec', 'exptime', 'fiberid', 'flux', 'id', 'instrument', 'ivar', 'mask', 'mjd', 'model', 'plate', 'ra', 'redshift', 'redshift_err', 'redshift_warning', 'run1d', 'run2d', 'site', 'sky', 'specid', 'specobjid', 'specprimary', 'spectype', 'targetid', 'telescope', 'wave_sigma', 'wavelength', 'wavemax', 'wavemin']
-    """
+    """  # noqa: E501
 
         common = set(self.fields.common(dataset_list))
         union = self.fields.all_retrieve_fields(dataset_list=dataset_list)
         return sorted(common.intersection(union))
 
     def _validate_science_fields(self, science_fields, *, dataset_list=None):
         """Raise exception if any field name in SCIENCE_FIELDS is
@@ -301,15 +302,15 @@
         Returns:
             Set of fields available from data sets in DATASET_LIST.
 
         Example:
             >>> client = SparclClient()
             >>> sorted(client.get_available_fields())
             ['data_release', 'datasetgroup', 'dateobs', 'dateobs_center', 'dec', 'dirpath', 'exptime', 'extra_files', 'fiberid', 'filename', 'filesize', 'flux', 'id', 'instrument', 'ivar', 'mask', 'mjd', 'model', 'plate', 'ra', 'redshift', 'redshift_err', 'redshift_warning', 'run1d', 'run2d', 'site', 'sky', 'specid', 'specobjid', 'specprimary', 'spectype', 'targetid', 'telescope', 'updated', 'wave_sigma', 'wavelength', 'wavemax', 'wavemin']
-        """
+        """  # noqa: E501
 
         drs = self.fields.all_drs if dataset_list is None else dataset_list
         every = [set(self.fields.n2o[dr]) for dr in drs]
         return set.intersection(*every)
 
     @property
     def version(self):
@@ -333,23 +334,22 @@
             self.apiversion = float(response.content)
         return self.apiversion
 
     def find(self, outfields=None, *,
              constraints={},  # dict(fname) = [op, param, ...]
              #dataset_list=None,
              limit=500,
-             sort=None,
-             verbose=None):
+             sort=None):
         """Find records in the SPARC database.
 
         Args:
             outfields (:obj:`list`, optional): List of fields to return.
                 Only CORE fields may be passed to this parameter.
-                Defaults to None, which will return only the id and _dr
-                fields.
+                Defaults to None, which will return only the sparcl_id
+                and _dr fields.
 
             constraints (:obj:`dict`, optional): Key-Value pairs of
                 constraints to place on the record selection. The Key
                 part of the Key-Value pair is the field name and the
                 Value part of the Key-Value pair is a list of values.
                 Defaults to no constraints. This will return all records in the
                 database subject to restrictions imposed by the ``limit``
@@ -357,17 +357,14 @@
 
             limit (:obj:`int`, optional): Maximum number of records to
                 return. Defaults to 500.
 
             sort (:obj:`list`, optional): Comma separated list of fields
                 to sort by. Defaults to None. (no sorting)
 
-            verbose (:obj:`bool`, optional): Set to True for in-depth return
-                statement. Defaults to False.
-
         Returns:
             :class:`~sparcl.Results.Found`: Contains header and records.
 
         Example:
             >>> client = SparclClient()
             >>> outs = ['id', 'ra', 'dec']
             >>> cons = {'spectype': ['GALAXY'], 'redshift': [0.5, 0.9]}
@@ -376,80 +373,72 @@
             ['_dr', 'dec', 'id', 'ra']
         """
         # dataset_list (:obj:`list`, optional): List of data sets from
         #     which to find records. Defaults to None, which
         #     will find records in all data sets hosted on the SPARC
         #     database.
 
-        verbose = self.verbose if verbose is None else verbose
-
         # Let "outfields" default to ['id']; but fld may have been renamed
         if outfields is None:
             dslist = list(self.fields.all_datasets)
             idfld = self.fields._science_name('id', dslist[0])
             if idfld not in self.fields.common():
                 msg = (f'The "id" field ("{idfld}" is not common to all '
                        f'current Data Sets ({(", ").join(dslist)}) '
                        f'so we cannot use the default outfields="{idfld}".'
                        )
                 raise ex.NoCommonIdField(msg)
             outfields = [idfld]
         dataset_list = self.fields.all_drs
-        #! self._validate_science_fields(outfields, dataset_list=dataset_list) # DLS-401
+        self._validate_science_fields(outfields, dataset_list=dataset_list)
         dr = list(dataset_list)[0]
         if len(constraints) > 0:
             self._validate_science_fields(constraints.keys(),
                                           dataset_list=dataset_list)
             constraints = {self.fields._internal_name(k, dr): v
                            for k, v in constraints.items()}
         uparams = dict(limit=limit,)
         if sort is not None:
             uparams['sort'] = sort
         qstr = urlencode(uparams)
         url = f'{self.apiurl}/find/?{qstr}'
-
         outfields = [self.fields._internal_name(s, dr) for s in outfields]
         search = [[k] + v for k, v in constraints.items()]
         sspec = dict(outfields=outfields, search=search)
-        if verbose:
-            print(f'url={url} sspec={sspec}')
         res = requests.post(url, json=sspec, timeout=self.timeout)
 
         if res.status_code != 200:
-            if verbose and ('traceback' in res.json()):
+            if self.verbose and ('traceback' in res.json()):
                 print(f'DBG: Server traceback=\n{res.json()["traceback"]}')
             raise ex.genSparclException(res, verbose=self.verbose)
 
-        found = Found(res.json(), client=self)
-        if verbose:
-            print(f'Record key counts: {ut.count_values(found.records)}')
-        return found
+        return Found(res.json(), client=self)
 
     def missing(self, uuid_list, *, dataset_list=None,
                 countOnly=False, verbose=False):
-        """Return the subset of ids in the given uuid_list that are NOT stored
-        in the SPARC database.
+        """Return the subset of sparcl_ids in the given uuid_list that are
+        NOT stored in the SPARC database.
 
         Args:
-            uuid_list (:obj:`list`): List of ids.
+            uuid_list (:obj:`list`): List of sparcl_ids.
 
             dataset_list (:obj:`list`, optional): List of data sets from
-                which to find missing ids. Defaults to None, meaning all
-                data sets hosted on the SPARC database.
+                which to find missing sparcl_ids. Defaults to None, meaning
+                all data sets hosted on the SPARC database.
 
             countOnly (:obj:`bool`, optional): Set to True to return only
-                a count of the missing ids from the uuid_list. Defaults to
-                False.
+                a count of the missing sparcl_ids from the uuid_list.
+                Defaults to False.
 
             verbose (:obj:`bool`, optional): Set to True for in-depth return
                 statement. Defaults to False.
 
         Returns:
-            A list of the subset of ids in the given uuid_list that are NOT
-            stored in the SPARC database.
+            A list of the subset of sparcl_ids in the given uuid_list that
+            are NOT stored in the SPARC database.
 
         Example:
             >>> client = SparclClient()
             >>> ids = ['ddbb57ee-8e90-4a0d-823b-0f5d97028076',]
             >>> client.missing(ids)
             ['ddbb57ee-8e90-4a0d-823b-0f5d97028076']
         """
@@ -507,18 +496,19 @@
                  svc='spectras',  # 'retrieve',
                  format='pkl',    # 'json',
                  include='DEFAULT',
                  dataset_list=None,
                  limit=500,
                  chunk=500,
                  verbose=None):
-        """Retrieve spectra records from the SPARC database by list of ids.
+        """Retrieve spectra records from the SPARC database by list of
+        sparcl_ids.
 
         Args:
-            uuid_list (:obj:`list`): List of ids.
+            uuid_list (:obj:`list`): List of sparcl_ids.
 
             svc (:obj:`str`, optional): Defaults to 'spectras'.
 
             format (:obj:`str`, optional): Defaults to 'pkl'.
 
             include (:obj:`list`, optional): List of field names to include
                 in each record. Defaults to 'DEFAULT', which will return
@@ -566,15 +556,15 @@
         self._validate_include(include_list, dataset_list)
 
         req_num = min(len(uuid_list), (limit or len(uuid_list)))
         #! print(f'DBG: req_num = {req_num:,d}'
         #!       f'  len(uuid_list)={len(uuid_list):,d}'
         #!       f'  limit={limit}'
         #!       f'  MAX_NUM_RECORDS_RETRIEVED={MAX_NUM_RECORDS_RETRIEVED:,d}')
-        if (req_num  >  MAX_NUM_RECORDS_RETRIEVED):
+        if (req_num > MAX_NUM_RECORDS_RETRIEVED):
             msg = (f'Too many records asked for with client.retrieve().'
                    f'  {len(uuid_list):,d} IDs provided,'
                    f'  limit={limit}.'
                    f'  But the maximum allowed is'
                    f' {MAX_NUM_RECORDS_RETRIEVED:,d}.')
             raise ex.TooManyRecords(msg)
```

## sparcl/exceptions.py

```diff
@@ -110,14 +110,15 @@
     error_code = 'BADSCONS'
 
 
 class NoRecords(BaseSparclException):
     """Results did not contain any records"""
     error_code = 'NORECORD'
 
+
 class TooManyRecords(BaseSparclException):
     """Too many records asked for in RETRIEVE"""
     error_code = 'TOOMANYR'
 
 
 class NoIDs(BaseSparclException):
     """The length of the list of original IDs passed to the reorder
```

## sparcl/fields.py

```diff
@@ -82,16 +82,15 @@
     def all_datasets(self):
         return self.all_drs
 
     def _science_name(self, internal_name, dataset):
         return self.o2n[dataset].get(internal_name)
 
     def _internal_name(self, science_name, dataset):
-        #!return self.n2o[dataset][science_name]
-        return self.n2o[dataset].get(science_name)
+        return self.n2o[dataset][science_name]
 
     def filter_fields(self, attr, dataset_list):
         fields = set()
         for dr in dataset_list:
             for k, v in self.attrs[dr].items():
                 if v.get(attr):
                     fields.add(k)
```

## sparcl/utils.py

```diff
@@ -1,12 +1,12 @@
 # Python library
+#!import os
 import datetime
 import time
 import socket
-import itertools
 # External packages
 #   none
 # LOCAL packages
 #   none
 
 
 # data = {
@@ -138,26 +138,7 @@
         tree = {showname: type(obj).__name__}
     return(tree)
 
 
 def invLUT(lut):
     """Given dict[k]=v, Return dict[v]=k"""
     return {v: k for k, v in lut.items()}
-
-def count_values(recs):
-    """Count number of non-None values in a list of dictionaries.
-    A key that exists with a value of None is treated the same as a
-    key that does not exist at all. i.e. It does not add to the count.
-
-    Args:
-       recs (:obj:`list`): ('records') List of dictionaries.
-
-    Returns:
-        A dictionary. Keys are the full list of keys available in any
-        of the recs.  Values are the count of occurances of non-None values
-        for that key.
-
-    >>> count_values([dict(a=None, b=3), dict(a=1, b=2), dict(a=None, b=2)])
-    {'a': 1, 'b': 3}
-    """
-    allkeys = set(list(itertools.chain(*recs)))
-    return {k: sum(x.get(k) is not None for x in recs) for k in allkeys}
```

## Comparing `sparclclient-1.2.0b3.dev7.dist-info/LICENSE` & `sparclclient-1.2.0b3.dev8.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `sparclclient-1.2.0b3.dev7.dist-info/METADATA` & `sparclclient-1.2.0b3.dev8.dist-info/METADATA`

 * *Files 1% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: sparclclient
-Version: 1.2.0b3.dev7
+Version: 1.2.0b3.dev8
 Summary: A client for getting spectra data from NOIRLab.
 Home-page: https://github.com/astro-datalab/sparclclient
 Author: NOIRLab DataLab
 Author-email: datalab-spectro@noirlab.edu
 Project-URL: Documentation, https://sparclclient.readthedocs.io/en/latest/
 Classifier: License :: OSI Approved :: BSD License
 Classifier: Programming Language :: Python :: 3.6
```

