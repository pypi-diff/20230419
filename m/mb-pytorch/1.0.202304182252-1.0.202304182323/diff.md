# Comparing `tmp/mb_pytorch-1.0.202304182252-py3-none-any.whl.zip` & `tmp/mb_pytorch-1.0.202304182323-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,18 +1,18 @@
-Zip file size: 32045 bytes, number of entries: 37
--rw-rw-r--  2.0 unx     4940 b- defN 23-Apr-18 22:36 mb_pytorch/classification/training.py
+Zip file size: 32067 bytes, number of entries: 37
+-rw-rw-r--  2.0 unx     5000 b- defN 23-Apr-18 23:01 mb_pytorch/classification/training.py
 -rw-rw-r--  2.0 unx       44 b- defN 23-Mar-16 11:39 mb_pytorch/dataloader/__init__.py
 -rw-rw-r--  2.0 unx    12157 b- defN 23-Apr-14 17:23 mb_pytorch/dataloader/loader.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Feb-23 13:56 mb_pytorch/metalearning/__init__.py
 -rw-rw-r--  2.0 unx     1385 b- defN 23-Mar-02 03:28 mb_pytorch/metalearning/meta_utils.py
 -rw-rw-r--  2.0 unx     1030 b- defN 23-Mar-15 02:58 mb_pytorch/metalearning/proto_dataloader.py
 -rw-rw-r--  2.0 unx     2861 b- defN 23-Mar-03 23:55 mb_pytorch/metalearning/prototypical.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Mar-31 19:54 mb_pytorch/models/__init__.py
 -rw-rw-r--  2.0 unx      920 b- defN 23-Mar-12 03:33 mb_pytorch/models/lenet.py
--rw-rw-r--  2.0 unx     4244 b- defN 23-Apr-17 18:00 mb_pytorch/models/modelloader.py
+-rw-rw-r--  2.0 unx     4245 b- defN 23-Apr-18 22:59 mb_pytorch/models/modelloader.py
 -rw-rw-r--  2.0 unx    10784 b- defN 23-Apr-01 03:27 mb_pytorch/models/unet_models.py
 -rw-rw-r--  2.0 unx        0 b- defN 23-Mar-31 19:54 mb_pytorch/models/blocks/__init__.py
 -rw-rw-r--  2.0 unx     2801 b- defN 23-Apr-01 00:43 mb_pytorch/models/blocks/attention_block.py
 -rw-rw-r--  2.0 unx     3629 b- defN 23-Mar-23 00:49 mb_pytorch/models/blocks/cnn.py
 -rw-rw-r--  2.0 unx     4783 b- defN 23-Mar-23 04:50 mb_pytorch/models/blocks/conv_block.py
 -rw-rw-r--  2.0 unx      920 b- defN 23-Mar-17 22:06 mb_pytorch/models/blocks/conv_with_relu.py
 -rw-rw-r--  2.0 unx     2256 b- defN 23-Mar-23 14:45 mb_pytorch/models/blocks/model_out.py
@@ -24,16 +24,16 @@
 -rw-rw-r--  2.0 unx        0 b- defN 23-Feb-23 13:56 mb_pytorch/utils/__init__.py
 -rw-rw-r--  2.0 unx     1055 b- defN 23-Mar-17 02:23 mb_pytorch/utils/compiler.py
 -rw-rw-r--  2.0 unx      257 b- defN 23-Mar-01 22:55 mb_pytorch/utils/dist.py
 -rw-rw-r--  2.0 unx     3391 b- defN 23-Apr-11 23:28 mb_pytorch/utils/extra_utils.py
 -rw-rw-r--  2.0 unx     7178 b- defN 23-Mar-15 02:58 mb_pytorch/utils/generate_emb.py
 -rw-rw-r--  2.0 unx     2582 b- defN 23-Apr-03 19:30 mb_pytorch/utils/losses.py
 -rw-rw-r--  2.0 unx     1199 b- defN 23-Apr-04 20:14 mb_pytorch/utils/metrics.py
--rw-rw-r--  2.0 unx     8806 b- defN 23-Apr-18 22:52 mb_pytorch/utils/viewer.py
+-rw-rw-r--  2.0 unx     8760 b- defN 23-Apr-18 22:54 mb_pytorch/utils/viewer.py
 -rw-rw-r--  2.0 unx      994 b- defN 23-Mar-06 13:11 mb_pytorch/utils/yaml_reader.py
--rwxrwxr-x  2.0 unx     1304 b- defN 23-Apr-18 22:52 mb_pytorch-1.0.202304182252.data/scripts/dataload_results.py
--rwxrwxr-x  2.0 unx      980 b- defN 23-Mar-15 02:59 mb_pytorch-1.0.202304182252.data/scripts/emb.py
--rw-rw-r--  2.0 unx      329 b- defN 23-Apr-18 22:52 mb_pytorch-1.0.202304182252.dist-info/METADATA
--rw-rw-r--  2.0 unx       92 b- defN 23-Apr-18 22:52 mb_pytorch-1.0.202304182252.dist-info/WHEEL
--rw-rw-r--  2.0 unx       11 b- defN 23-Apr-18 22:52 mb_pytorch-1.0.202304182252.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     3348 b- defN 23-Apr-18 22:52 mb_pytorch-1.0.202304182252.dist-info/RECORD
-37 files, 93492 bytes uncompressed, 26579 bytes compressed:  71.6%
+-rwxrwxr-x  2.0 unx     1304 b- defN 23-Apr-18 23:24 mb_pytorch-1.0.202304182323.data/scripts/dataload_results.py
+-rwxrwxr-x  2.0 unx      980 b- defN 23-Mar-15 02:59 mb_pytorch-1.0.202304182323.data/scripts/emb.py
+-rw-rw-r--  2.0 unx      329 b- defN 23-Apr-18 23:24 mb_pytorch-1.0.202304182323.dist-info/METADATA
+-rw-rw-r--  2.0 unx       92 b- defN 23-Apr-18 23:24 mb_pytorch-1.0.202304182323.dist-info/WHEEL
+-rw-rw-r--  2.0 unx       11 b- defN 23-Apr-18 23:24 mb_pytorch-1.0.202304182323.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     3348 b- defN 23-Apr-18 23:24 mb_pytorch-1.0.202304182323.dist-info/RECORD
+37 files, 93507 bytes uncompressed, 26601 bytes compressed:  71.6%
```

## zipnote {}

```diff
@@ -87,26 +87,26 @@
 
 Filename: mb_pytorch/utils/viewer.py
 Comment: 
 
 Filename: mb_pytorch/utils/yaml_reader.py
 Comment: 
 
-Filename: mb_pytorch-1.0.202304182252.data/scripts/dataload_results.py
+Filename: mb_pytorch-1.0.202304182323.data/scripts/dataload_results.py
 Comment: 
 
-Filename: mb_pytorch-1.0.202304182252.data/scripts/emb.py
+Filename: mb_pytorch-1.0.202304182323.data/scripts/emb.py
 Comment: 
 
-Filename: mb_pytorch-1.0.202304182252.dist-info/METADATA
+Filename: mb_pytorch-1.0.202304182323.dist-info/METADATA
 Comment: 
 
-Filename: mb_pytorch-1.0.202304182252.dist-info/WHEEL
+Filename: mb_pytorch-1.0.202304182323.dist-info/WHEEL
 Comment: 
 
-Filename: mb_pytorch-1.0.202304182252.dist-info/top_level.txt
+Filename: mb_pytorch-1.0.202304182323.dist-info/top_level.txt
 Comment: 
 
-Filename: mb_pytorch-1.0.202304182252.dist-info/RECORD
+Filename: mb_pytorch-1.0.202304182323.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## mb_pytorch/classification/training.py

```diff
@@ -95,15 +95,15 @@
     
         model.eval()
         with torch.no_grad():
             for x_val, y_val in val_loader:
                 x_val, y_val = x_val.to(device), y_val.to(device)
                 output = model(x_val)
                 val_loss += loss_attr(output, y_val).item() * x_val.size(0)
-                _, preds = torch.max(output, 1)
+                _, preds = torch.max(output, 1) #no need of softmax. max returns the index of the max value
                 val_acc += torch.sum(preds == y_val.data)
                 new_val_loss = val_loss/len(val_loader.dataset)
                 num_samples += x_val.size(0)
                 if logger: 
                     logger.info(f'Epoch {i+1} - Batch {j+1} - Val Loss: {new_val_loss:.3f}')
             
             avg_val_loss = val_loss / len(val_loader.dataset)
```

## mb_pytorch/models/modelloader.py

```diff
@@ -53,15 +53,15 @@
             if hasattr(model_out,'classifier'):
                 for module in list(model_out.modules()):
                     if isinstance(module, nn.Linear):
                         first_layer = module
                         num_ftrs = first_layer.in_features
                         model_out.classifier = nn.Linear(num_ftrs, self._model_num_classes)
                         break
-            model_out.softmax = nn.Softmax(dim=1)
+            #model_out.softmax = nn.Softmax(dim=1)
         
             
         #     for module in reversed(list(model_out.modules())):
         #         if isinstance(module, nn.Linear):
         #             last_layer = module
         #             num_ftrs = last_layer.in_features
         #             model_out.classifier = nn.Linear(num_ftrs, self._model_num_classes)
```

## mb_pytorch/utils/viewer.py

```diff
@@ -70,25 +70,24 @@
             subplot_kw = {'xticks':[], 'yticks':[]},
             gridspec_kw = dict(hspace=0.3, wspace=0.01))
     
     if gray_image:
         for i, ax in enumerate(axes.flat):
             img_cur = np.array(data_read[i,0,:,:])
             ax.title.set_text(int(labels_read[i]))
-            ax.imshow(img_cur, cmap='gray')
+            #ax.imshow(img_cur, cmap='gray')
     else:
         for i, ax in enumerate(axes.flat):
             img_cur = np.array(data_read[i])
             img_cur = np.transpose(img_cur, (1, 2, 0))
             ax.title.set_text(int(labels_read[i]))
-            ax.imshow(img_cur)
+            #ax.imshow(img_cur)
     
     ### Send the figure over to TensorBoard
     t_writer.add_image('grid', plot_to_image(fig), global_step=global_step)
-    print('Written image grid to TensorBoard.')
 
 
 def show_segmentation_masks(imgs, masks, figsize=(12.0, 12.0)):
     """Displays a single image or list of images with segmentation masks.
     Args:
         imgs (Union[List[torch.Tensor], torch.Tensor]): A list of images
             of shape (3, H, W) or a single image of shape (3, H, W).
```

## Comparing `mb_pytorch-1.0.202304182252.data/scripts/dataload_results.py` & `mb_pytorch-1.0.202304182323.data/scripts/dataload_results.py`

 * *Files identical despite different names*

## Comparing `mb_pytorch-1.0.202304182252.data/scripts/emb.py` & `mb_pytorch-1.0.202304182323.data/scripts/emb.py`

 * *Files identical despite different names*

## Comparing `mb_pytorch-1.0.202304182252.dist-info/RECORD` & `mb_pytorch-1.0.202304182323.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
-mb_pytorch/classification/training.py,sha256=DDgvfJ1fBbHaYZMd32vgKrAFkwCml2NWKPLrNU89Vck,4940
+mb_pytorch/classification/training.py,sha256=FMfxCnWCmlyrjivOKDiaUQYH-803oj8XWHF4A4YA8jg,5000
 mb_pytorch/dataloader/__init__.py,sha256=nB0xPAHbI91Ra1dDkWR1l4td5A4k9xko-I5Jdgv5apI,44
 mb_pytorch/dataloader/loader.py,sha256=oD73gXl4LP1ValUsNrtNySexiKjx1CvZPHNqWTC3c-g,12157
 mb_pytorch/metalearning/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mb_pytorch/metalearning/meta_utils.py,sha256=mgHYiQIIcYQ1pVTJcrjquSXpQstdYD1q8iXO09Zao1s,1385
 mb_pytorch/metalearning/proto_dataloader.py,sha256=WvrfZYkYMxorocCkR_zHS_AC8W_ML9YndB-P6evkdcc,1030
 mb_pytorch/metalearning/prototypical.py,sha256=qFVf6VF3s8zskGqbM3geJV-dfkdO3tRaf3P8U_KR-cE,2861
 mb_pytorch/models/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mb_pytorch/models/lenet.py,sha256=vZpN0LsfVGNI6z91YO3GLPCVB9Sv0EAxaTwEavRSKKo,920
-mb_pytorch/models/modelloader.py,sha256=qR0markcjrL87GkKVKw0dCoOtx-VH57w-p4fVM_HU4U,4244
+mb_pytorch/models/modelloader.py,sha256=N1PMwZWQ86zB1O-45lqfQRemWNfDqOIpbkWEtkb-ueU,4245
 mb_pytorch/models/unet_models.py,sha256=8AYw1MaFRUPLkfyyPmAaVZol2lRY28oiTjZRgZVRa4s,10784
 mb_pytorch/models/blocks/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mb_pytorch/models/blocks/attention_block.py,sha256=jMkfI79upW-PDc28dQ17s34gUR0gCpMB0XIpGgFDE_Q,2801
 mb_pytorch/models/blocks/cnn.py,sha256=IFPDIkKb-LyfzqK9RshqzNidSDdfrRmMylADYvWGACE,3629
 mb_pytorch/models/blocks/conv_block.py,sha256=vlcJiBwkbbmhQMpGLzQA0S14Wkw1Ai9adSbOquFBk0c,4783
 mb_pytorch/models/blocks/conv_with_relu.py,sha256=WIwJBfzvp-kE8QY6Ts5wg0ioJAcJIvmqKLpSl46j_II,920
 mb_pytorch/models/blocks/model_out.py,sha256=JmtY1zHCtkj-RbEVhQ8e6EvXd5WWVLrP9Lb_FigO7rA,2256
@@ -23,15 +23,15 @@
 mb_pytorch/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 mb_pytorch/utils/compiler.py,sha256=ixu-wc--ykhsjXTZINw34MLmZFg7L-dLkYs7p-nn6i4,1055
 mb_pytorch/utils/dist.py,sha256=7-ZdntmiugRWYnT5wileo8mYTuV1dbjVl4ffJsfnfAw,257
 mb_pytorch/utils/extra_utils.py,sha256=-MaT-x3gwgEOVLpg-tWm5yLFtI0CxpV0QUlXx-rqu08,3391
 mb_pytorch/utils/generate_emb.py,sha256=2iK8wRIrYfaLpEgjdbFnDqGU5ux-1JhncQoeboW_6LQ,7178
 mb_pytorch/utils/losses.py,sha256=OLCPLkJH46IofSSVly2xdcklVv7Q5OFFEGtVrJcV7V0,2582
 mb_pytorch/utils/metrics.py,sha256=Kqmdu9llSjR8aRp3IVlmy6PqeQexf0ZXjTJUcEtvcfI,1199
-mb_pytorch/utils/viewer.py,sha256=jaPBsdx8Ob_C1lHvnrHnsODVcMc2irxL1qKy0tryRkg,8806
+mb_pytorch/utils/viewer.py,sha256=ewGics_ddDD5PNI6vRcsKBMdC4fo1S90hHh8bOWe2u8,8760
 mb_pytorch/utils/yaml_reader.py,sha256=Azgr_5qttsH_BBVsCtfccFMvK6IEjTRYhd5qp4S5uzk,994
-mb_pytorch-1.0.202304182252.data/scripts/dataload_results.py,sha256=8IFAH7WX-nSJ7V532rr3Cl7R37v0jhSakw0JCd9dalE,1304
-mb_pytorch-1.0.202304182252.data/scripts/emb.py,sha256=5jSbTGNOhusDTvHZeaTwk4pmJa4HIdkRGd98s0L4Rl0,980
-mb_pytorch-1.0.202304182252.dist-info/METADATA,sha256=sQ1Wx3jP6CRrtJdd5rJ53nEHXLzzlrX7YoNF4bhzhpE,329
-mb_pytorch-1.0.202304182252.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-mb_pytorch-1.0.202304182252.dist-info/top_level.txt,sha256=2m_aBiEfjq3pZM2NtYSlTqlgoQxH6WaK8_8SsRicIvg,11
-mb_pytorch-1.0.202304182252.dist-info/RECORD,,
+mb_pytorch-1.0.202304182323.data/scripts/dataload_results.py,sha256=8IFAH7WX-nSJ7V532rr3Cl7R37v0jhSakw0JCd9dalE,1304
+mb_pytorch-1.0.202304182323.data/scripts/emb.py,sha256=5jSbTGNOhusDTvHZeaTwk4pmJa4HIdkRGd98s0L4Rl0,980
+mb_pytorch-1.0.202304182323.dist-info/METADATA,sha256=NWfJHdPX4VJ41hgNkaBC57Zv0uAgH4Q_QUWBBNKQL9Q,329
+mb_pytorch-1.0.202304182323.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
+mb_pytorch-1.0.202304182323.dist-info/top_level.txt,sha256=2m_aBiEfjq3pZM2NtYSlTqlgoQxH6WaK8_8SsRicIvg,11
+mb_pytorch-1.0.202304182323.dist-info/RECORD,,
```

